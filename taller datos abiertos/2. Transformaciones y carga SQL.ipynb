{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a trabajar con los archivos de extensión csv que están en la carpeta \"Bases saludo taller\" en el mismo directorio de mi script. \n",
    "Dame el codigo en python para iterar sobre todos los archivos csv para obtener el nombre de sus columnas y genera una tabla donde me los muestres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas extraídas exitosamente de DA_EC_SIS_2010.csv con codificación utf-8\n",
      "Columnas extraídas exitosamente de DA_EC_SIS_2011.csv con codificación utf-8\n",
      "Columnas extraídas exitosamente de DA_EC_SIS_2012.csv con codificación utf-8\n",
      "Columnas extraídas exitosamente de DA_EC_SIS_2013.csv con codificación utf-8\n",
      "Columnas extraídas exitosamente de DA_EC_SIS_2014.csv con codificación utf-8\n",
      "Columnas extraídas exitosamente de DA_EC_SIS_2015.csv con codificación utf-8\n",
      "Columnas extraídas exitosamente de DA_EC_SIS_2016.csv con codificación utf-8\n",
      "Columnas extraídas exitosamente de DA_EC_SIS_2017.csv con codificación utf-8\n",
      "Columnas extraídas exitosamente de DA_EC_SIS_2018.csv con codificación utf-8\n",
      "Columnas extraídas exitosamente de DA_EC_SIS_2019.csv con codificación utf-8\n",
      "Columnas extraídas exitosamente de DA_EC_SIS_2020.csv con codificación utf-8\n",
      "Columnas extraídas exitosamente de DA_EC_SIS_2021.csv con codificación utf-8\n",
      "Columnas extraídas exitosamente de DA_EC_SIS_2022.csv con codificación utf-8\n",
      "Columnas extraídas exitosamente de DA_EC_SIS_2023.csv con codificación utf-8\n",
      "               Archivo  \\\n",
      "0   DA_EC_SIS_2010.csv   \n",
      "1   DA_EC_SIS_2011.csv   \n",
      "2   DA_EC_SIS_2012.csv   \n",
      "3   DA_EC_SIS_2013.csv   \n",
      "4   DA_EC_SIS_2014.csv   \n",
      "5   DA_EC_SIS_2015.csv   \n",
      "6   DA_EC_SIS_2016.csv   \n",
      "7   DA_EC_SIS_2017.csv   \n",
      "8   DA_EC_SIS_2018.csv   \n",
      "9   DA_EC_SIS_2019.csv   \n",
      "10  DA_EC_SIS_2020.csv   \n",
      "11  DA_EC_SIS_2021.csv   \n",
      "12  DA_EC_SIS_2022.csv   \n",
      "13  DA_EC_SIS_2023.csv   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Columnas  \n",
      "0                                                                                                                   Clave_Entidad, Entidad, Clave_Municipio, Municipio, CLUES, Nombre_CLUES, Mes, Anio, ADM02, ADM03, ADM05, ADM06, ADM08, ADM09, ADM11, ADM12, ADM14, ADM15, ADM17, ADM18, AHA02, AHA03, AHA05, AHA06, AHA08, AHA09, AHA11, AHA12, AHA14, AHA15, AHA17, AHA18, AOB02, AOB03, AOB05, AOB06, AOB08, AOB09, AOB11, AOB12, AOB14, AOB15, AOB17, AOB18, ADL02, ADL03, ADL05, ADL06, ADL08, ADL09, ADL11, ADL12, ADL14, ADL15, ADL17, ADL18, AEC02, AEC03, AEC05, AEC06, AEC08, AEC09, AEC11, AEC12, AEC14, AEC15, AEC17, AEC18, PDM01  \n",
      "1                                                                                                                   Clave_Entidad, Entidad, Clave_Municipio, Municipio, CLUES, Nombre_CLUES, Mes, Anio, ADM02, ADM03, ADM05, ADM06, ADM08, ADM09, ADM11, ADM12, ADM14, ADM15, ADM17, ADM18, AHA02, AHA03, AHA05, AHA06, AHA08, AHA09, AHA11, AHA12, AHA14, AHA15, AHA17, AHA18, AOB02, AOB03, AOB05, AOB06, AOB08, AOB09, AOB11, AOB12, AOB14, AOB15, AOB17, AOB18, ADL02, ADL03, ADL05, ADL06, ADL08, ADL09, ADL11, ADL12, ADL14, ADL15, ADL17, ADL18, AEC02, AEC03, AEC05, AEC06, AEC08, AEC09, AEC11, AEC12, AEC14, AEC15, AEC17, AEC18, PDM01  \n",
      "2                                                                                                                   Clave_Entidad, Entidad, Clave_Municipio, Municipio, CLUES, Nombre_CLUES, Mes, Anio, ADM02, ADM03, ADM05, ADM06, ADM08, ADM09, ADM11, ADM12, ADM14, ADM15, ADM17, ADM18, AHA02, AHA03, AHA05, AHA06, AHA08, AHA09, AHA11, AHA12, AHA14, AHA15, AHA17, AHA18, AOB02, AOB03, AOB05, AOB06, AOB08, AOB09, AOB11, AOB12, AOB14, AOB15, AOB17, AOB18, ADL02, ADL03, ADL05, ADL06, ADL08, ADL09, ADL11, ADL12, ADL14, ADL15, ADL17, ADL18, AEC02, AEC03, AEC05, AEC06, AEC08, AEC09, AEC11, AEC12, AEC14, AEC15, AEC17, AEC18, PDM01  \n",
      "3                                                                                                     Clave_Entidad, Entidad, Clave_Municipio, Municipio, CLUES, Nombre_CLUES, Mes, Anio, ADM02, ADM03, ADM05, ADM06, ADM08, ADM09, ADM11, ADM12, ADM14, ADM15, ADM17, ADM18, AHA02, AHA03, AHA05, AHA06, AHA08, AHA09, AHA11, AHA12, AHA14, AHA15, AHA17, AHA18, AOB02, AOB03, AOB05, AOB06, AOB08, AOB09, AOB11, AOB12, AOB14, AOB15, AOB17, AOB18, ADL02, ADL03, ADL05, ADL06, ADL08, ADL09, ADL11, ADL12, ADL14, ADL15, ADL17, ADL18, AEC02, AEC03, AEC05, AEC06, AEC08, AEC09, AEC11, AEC12, AEC14, AEC15, AEC17, AEC18, PDM01, RHP01, RHP02  \n",
      "4                                                                                                     Clave_Entidad, Entidad, Clave_Municipio, Municipio, CLUES, Nombre_CLUES, Mes, Anio, ADM02, ADM03, ADM05, ADM06, ADM08, ADM09, ADM11, ADM12, ADM14, ADM15, ADM17, ADM18, AHA02, AHA03, AHA05, AHA06, AHA08, AHA09, AHA11, AHA12, AHA14, AHA15, AHA17, AHA18, AOB02, AOB03, AOB05, AOB06, AOB08, AOB09, AOB11, AOB12, AOB14, AOB15, AOB17, AOB18, ADL02, ADL03, ADL05, ADL06, ADL08, ADL09, ADL11, ADL12, ADL14, ADL15, ADL17, ADL18, AEC02, AEC03, AEC05, AEC06, AEC08, AEC09, AEC11, AEC12, AEC14, AEC15, AEC17, AEC18, PDM01, RHP01, RHP02  \n",
      "5                                                                                       Clave_Entidad, Entidad, Clave_Municipio, Municipio, CLUES, Nombre_CLUES, Mes, Anio, ADM02, ADM03, ADM05, ADM06, ADM08, ADM09, ADM11, ADM12, ADM14, ADM15, ADM17, ADM18, AHA02, AHA03, AHA05, AHA06, AHA08, AHA09, AHA11, AHA12, AHA14, AHA15, AHA17, AHA18, AOB02, AOB03, AOB05, AOB06, AOB08, AOB09, AOB11, AOB12, AOB14, AOB15, AOB17, AOB18, ADL02, ADL03, ADL05, ADL06, ADL08, ADL09, ADL11, ADL12, ADL14, ADL15, ADL17, ADL18, AEC02, AEC03, AEC05, AEC06, AEC08, AEC09, AEC11, AEC12, AEC14, AEC15, AEC17, AEC18, HBA01, HBA02, HBA03, PDM02, PDM03  \n",
      "6                                             Clave_Entidad, Entidad, Clave_Municipio, Municipio, CLUES, Nombre_CLUES, Mes, Anio, ADM02, ADM03, ADM05, ADM06, ADM08, ADM09, ADM11, ADM12, ADM14, ADM15, ADM17, ADM18, AHA02, AHA03, AHA05, AHA06, AHA08, AHA09, AHA11, AHA12, AHA14, AHA15, AHA17, AHA18, AOB02, AOB03, AOB05, AOB06, AOB08, AOB09, AOB11, AOB12, AOB14, AOB15, AOB17, AOB18, ADL02, ADL03, ADL05, ADL06, ADL08, ADL09, ADL11, ADL12, ADL14, ADL15, ADL17, ADL18, AEC02, AEC03, AEC05, AEC06, AEC08, AEC09, AEC11, AEC12, AEC14, AEC15, AEC17, AEC18, FRS01, FRS02, FRS03, FRS04, HBA01, HBA02, HBA03, PMA01, PDM02, PDM03, RUN01  \n",
      "7                                             Clave_Entidad, Entidad, Clave_Municipio, Municipio, CLUES, Nombre_CLUES, Mes, Anio, ADM02, ADM03, ADM05, ADM06, ADM08, ADM09, ADM11, ADM12, ADM14, ADM15, ADM17, ADM18, AHA02, AHA03, AHA05, AHA06, AHA08, AHA09, AHA11, AHA12, AHA14, AHA15, AHA17, AHA18, AOB02, AOB03, AOB05, AOB06, AOB08, AOB09, AOB11, AOB12, AOB14, AOB15, AOB17, AOB18, ADL02, ADL03, ADL05, ADL06, ADL08, ADL09, ADL11, ADL12, ADL14, ADL15, ADL17, ADL18, AEC02, AEC03, AEC05, AEC06, AEC08, AEC09, AEC11, AEC12, AEC14, AEC15, AEC17, AEC18, FRS01, FRS02, FRS03, FRS04, HBA01, HBA02, HBA03, PMA01, PDM02, PDM03, RUN01  \n",
      "8                                             Clave_Entidad, Entidad, Clave_Municipio, Municipio, CLUES, Nombre_CLUES, Mes, Anio, ADM02, ADM03, ADM05, ADM06, ADM08, ADM09, ADM11, ADM12, ADM14, ADM15, ADM17, ADM18, AHA02, AHA03, AHA05, AHA06, AHA08, AHA09, AHA11, AHA12, AHA14, AHA15, AHA17, AHA18, AOB02, AOB03, AOB05, AOB06, AOB08, AOB09, AOB11, AOB12, AOB14, AOB15, AOB17, AOB18, ADL02, ADL03, ADL05, ADL06, ADL08, ADL09, ADL11, ADL12, ADL14, ADL15, ADL17, ADL18, AEC02, AEC03, AEC05, AEC06, AEC08, AEC09, AEC11, AEC12, AEC14, AEC15, AEC17, AEC18, FRS01, FRS02, FRS03, FRS04, HBA01, HBA02, HBA03, PMA01, PDM02, PDM03, RUN01  \n",
      "9                                             Clave_Entidad, Entidad, Clave_Municipio, Municipio, CLUES, Nombre_CLUES, Mes, Anio, ADM02, ADM03, ADM05, ADM06, ADM08, ADM09, ADM11, ADM12, ADM14, ADM15, ADM17, ADM18, AHA02, AHA03, AHA05, AHA06, AHA08, AHA09, AHA11, AHA12, AHA14, AHA15, AHA17, AHA18, AOB02, AOB03, AOB05, AOB06, AOB08, AOB09, AOB11, AOB12, AOB14, AOB15, AOB17, AOB18, ADL02, ADL03, ADL05, ADL06, ADL08, ADL09, ADL11, ADL12, ADL14, ADL15, ADL17, ADL18, AEC02, AEC03, AEC05, AEC06, AEC08, AEC09, AEC11, AEC12, AEC14, AEC15, AEC17, AEC18, FRS01, FRS02, FRS03, FRS04, HBA01, HBA02, HBA03, PMA01, PDM02, PDM03, RUN01  \n",
      "10                                            Clave_Entidad, Entidad, Clave_Municipio, Municipio, CLUES, Nombre_CLUES, MES, ANIO, ADL02, ADL03, ADL05, ADL06, ADL08, ADL09, ADL11, ADL12, ADL14, ADL15, ADL17, ADL18, ADM02, ADM03, ADM05, ADM06, ADM08, ADM09, ADM11, ADM12, ADM14, ADM15, ADM17, ADM18, AEC02, AEC03, AEC05, AEC06, AEC08, AEC09, AEC11, AEC12, AEC14, AEC15, AEC17, AEC18, AHA02, AHA03, AHA05, AHA06, AHA08, AHA09, AHA11, AHA12, AHA14, AHA15, AHA17, AHA18, AOB02, AOB03, AOB05, AOB06, AOB08, AOB09, AOB11, AOB12, AOB14, AOB15, AOB17, AOB18, FRS01, FRS02, FRS03, FRS04, HBA01, HBA02, HBA03, PDM02, PDM03, PMA01, RUN01  \n",
      "11  CLAVE_ENTIDAD, ENTIDAD, CLAVE_MUNICIPIO, MUNICIPIO, CLUES, NOMBRE_CLUES, MES, ANIO, ADL02, ADL03, ADL05, ADL06, ADL08, ADL09, ADL11, ADL12, ADL14, ADL15, ADL17, ADL18, ADM02, ADM03, ADM05, ADM06, ADM08, ADM09, ADM11, ADM12, ADM14, ADM15, ADM17, ADM18, ADM19, ADM20, ADM21, ADM22, ADM23, AEC02, AEC03, AEC05, AEC06, AEC08, AEC09, AEC11, AEC12, AEC14, AEC15, AEC17, AEC18, AHA02, AHA03, AHA05, AHA06, AHA08, AHA09, AHA11, AHA12, AHA14, AHA15, AHA17, AHA18, AOB02, AOB03, AOB05, AOB06, AOB08, AOB09, AOB11, AOB12, AOB14, AOB15, AOB17, AOB18, FRS01, FRS02, FRS03, FRS04, HBA01, HBA02, HBA03, PDM02, PDM03, PMA01, PMA02, RUN01  \n",
      "12  CLAVE_ENTIDAD, ENTIDAD, CLAVE_MUNICIPIO, MUNICIPIO, CLUES, NOMBRE_CLUES, MES, ANIO, ADL02, ADL03, ADL05, ADL06, ADL08, ADL09, ADL11, ADL12, ADL14, ADL15, ADL17, ADL18, ADM02, ADM03, ADM05, ADM06, ADM08, ADM09, ADM11, ADM12, ADM14, ADM15, ADM17, ADM18, ADM19, ADM20, ADM21, ADM22, ADM23, AEC02, AEC03, AEC05, AEC06, AEC08, AEC09, AEC11, AEC12, AEC14, AEC15, AEC17, AEC18, AHA02, AHA03, AHA05, AHA06, AHA08, AHA09, AHA11, AHA12, AHA14, AHA15, AHA17, AHA18, AOB02, AOB03, AOB05, AOB06, AOB08, AOB09, AOB11, AOB12, AOB14, AOB15, AOB17, AOB18, FRS01, FRS02, FRS03, FRS04, HBA01, HBA02, HBA03, PDM02, PDM03, PMA01, PMA02, RUN01  \n",
      "13  CLAVE_ENTIDAD, ENTIDAD, CLAVE_MUNICIPIO, MUNICIPIO, CLUES, NOMBRE_CLUES, MES, ANIO, ADL02, ADL03, ADL05, ADL06, ADL08, ADL09, ADL11, ADL12, ADL14, ADL15, ADL17, ADL18, ADM02, ADM03, ADM05, ADM06, ADM08, ADM09, ADM11, ADM12, ADM14, ADM15, ADM17, ADM18, ADM19, ADM20, ADM21, ADM22, ADM23, AEC02, AEC03, AEC05, AEC06, AEC08, AEC09, AEC11, AEC12, AEC14, AEC15, AEC17, AEC18, AHA02, AHA03, AHA05, AHA06, AHA08, AHA09, AHA11, AHA12, AHA14, AHA15, AHA17, AHA18, AOB02, AOB03, AOB05, AOB06, AOB08, AOB09, AOB11, AOB12, AOB14, AOB15, AOB17, AOB18, FRS01, FRS02, FRS03, FRS04, HBA01, HBA02, HBA03, PDM02, PDM03, PMA01, PMA02, RUN01  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directorio donde se encuentran los archivos CSV\n",
    "directory = \"Bases saludo taller\"\n",
    "\n",
    "# Lista para almacenar la información de las columnas\n",
    "csv_columns_info = []\n",
    "\n",
    "# Iterar sobre los archivos en el directorio\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "\n",
    "        # Intentar leer con diferentes codificaciones\n",
    "        encodings = [\"utf-8\", \"latin1\", \"iso-8859-1\"]\n",
    "        for encoding in encodings:\n",
    "            try:\n",
    "                # Leer solo la primera fila para obtener los nombres de las columnas\n",
    "                df = pd.read_csv(file_path, nrows=0, encoding=encoding)\n",
    "                columns = df.columns.tolist()\n",
    "\n",
    "                # Almacenar el nombre del archivo y sus columnas\n",
    "                csv_columns_info.append({\n",
    "                    \"Archivo\": filename,\n",
    "                    \"Columnas\": \", \".join(columns)\n",
    "                })\n",
    "\n",
    "                print(f\"Columnas extraídas exitosamente de {filename} con codificación {encoding}\")\n",
    "                break  # Salir del bucle si la lectura fue exitosa\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error al procesar {filename} con codificación {encoding}: {e}\")\n",
    "\n",
    "# Convertir la información en un DataFrame para mejor visualización\n",
    "columns_df = pd.DataFrame(csv_columns_info)\n",
    "\n",
    "# Configurar pandas para mostrar el contenido completo de las columnas y todas las filas\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Mostrar la tabla de archivos y sus columnas\n",
    "print(columns_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Archivo</th>\n",
       "      <th>Columnas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DA_EC_SIS_2010.csv</td>\n",
       "      <td>Clave_Entidad, Entidad, Clave_Municipio, Municipio, CLUES, Nombre_CLUES, Mes, Anio, ADM02, ADM03, ADM05, ADM06, ADM08, ADM09, ADM11, ADM12, ADM14, ADM15, ADM17, ADM18, AHA02, AHA03, AHA05, AHA06, AHA08, AHA09, AHA11, AHA12, AHA14, AHA15, AHA17, AHA18, AOB02, AOB03, AOB05, AOB06, AOB08, AOB09, AOB11, AOB12, AOB14, AOB15, AOB17, AOB18, ADL02, ADL03, ADL05, ADL06, ADL08, ADL09, ADL11, ADL12, ADL14, ADL15, ADL17, ADL18, AEC02, AEC03, AEC05, AEC06, AEC08, AEC09, AEC11, AEC12, AEC14, AEC15, AEC17, AEC18, PDM01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DA_EC_SIS_2011.csv</td>\n",
       "      <td>Clave_Entidad, Entidad, Clave_Municipio, Municipio, CLUES, Nombre_CLUES, Mes, Anio, ADM02, ADM03, ADM05, ADM06, ADM08, ADM09, ADM11, ADM12, ADM14, ADM15, ADM17, ADM18, AHA02, AHA03, AHA05, AHA06, AHA08, AHA09, AHA11, AHA12, AHA14, AHA15, AHA17, AHA18, AOB02, AOB03, AOB05, AOB06, AOB08, AOB09, AOB11, AOB12, AOB14, AOB15, AOB17, AOB18, ADL02, ADL03, ADL05, ADL06, ADL08, ADL09, ADL11, ADL12, ADL14, ADL15, ADL17, ADL18, AEC02, AEC03, AEC05, AEC06, AEC08, AEC09, AEC11, AEC12, AEC14, AEC15, AEC17, AEC18, PDM01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DA_EC_SIS_2012.csv</td>\n",
       "      <td>Clave_Entidad, Entidad, Clave_Municipio, Municipio, CLUES, Nombre_CLUES, Mes, Anio, ADM02, ADM03, ADM05, ADM06, ADM08, ADM09, ADM11, ADM12, ADM14, ADM15, ADM17, ADM18, AHA02, AHA03, AHA05, AHA06, AHA08, AHA09, AHA11, AHA12, AHA14, AHA15, AHA17, AHA18, AOB02, AOB03, AOB05, AOB06, AOB08, AOB09, AOB11, AOB12, AOB14, AOB15, AOB17, AOB18, ADL02, ADL03, ADL05, ADL06, ADL08, ADL09, ADL11, ADL12, ADL14, ADL15, ADL17, ADL18, AEC02, AEC03, AEC05, AEC06, AEC08, AEC09, AEC11, AEC12, AEC14, AEC15, AEC17, AEC18, PDM01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DA_EC_SIS_2013.csv</td>\n",
       "      <td>Clave_Entidad, Entidad, Clave_Municipio, Municipio, CLUES, Nombre_CLUES, Mes, Anio, ADM02, ADM03, ADM05, ADM06, ADM08, ADM09, ADM11, ADM12, ADM14, ADM15, ADM17, ADM18, AHA02, AHA03, AHA05, AHA06, AHA08, AHA09, AHA11, AHA12, AHA14, AHA15, AHA17, AHA18, AOB02, AOB03, AOB05, AOB06, AOB08, AOB09, AOB11, AOB12, AOB14, AOB15, AOB17, AOB18, ADL02, ADL03, ADL05, ADL06, ADL08, ADL09, ADL11, ADL12, ADL14, ADL15, ADL17, ADL18, AEC02, AEC03, AEC05, AEC06, AEC08, AEC09, AEC11, AEC12, AEC14, AEC15, AEC17, AEC18, PDM01, RHP01, RHP02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DA_EC_SIS_2014.csv</td>\n",
       "      <td>Clave_Entidad, Entidad, Clave_Municipio, Municipio, CLUES, Nombre_CLUES, Mes, Anio, ADM02, ADM03, ADM05, ADM06, ADM08, ADM09, ADM11, ADM12, ADM14, ADM15, ADM17, ADM18, AHA02, AHA03, AHA05, AHA06, AHA08, AHA09, AHA11, AHA12, AHA14, AHA15, AHA17, AHA18, AOB02, AOB03, AOB05, AOB06, AOB08, AOB09, AOB11, AOB12, AOB14, AOB15, AOB17, AOB18, ADL02, ADL03, ADL05, ADL06, ADL08, ADL09, ADL11, ADL12, ADL14, ADL15, ADL17, ADL18, AEC02, AEC03, AEC05, AEC06, AEC08, AEC09, AEC11, AEC12, AEC14, AEC15, AEC17, AEC18, PDM01, RHP01, RHP02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DA_EC_SIS_2015.csv</td>\n",
       "      <td>Clave_Entidad, Entidad, Clave_Municipio, Municipio, CLUES, Nombre_CLUES, Mes, Anio, ADM02, ADM03, ADM05, ADM06, ADM08, ADM09, ADM11, ADM12, ADM14, ADM15, ADM17, ADM18, AHA02, AHA03, AHA05, AHA06, AHA08, AHA09, AHA11, AHA12, AHA14, AHA15, AHA17, AHA18, AOB02, AOB03, AOB05, AOB06, AOB08, AOB09, AOB11, AOB12, AOB14, AOB15, AOB17, AOB18, ADL02, ADL03, ADL05, ADL06, ADL08, ADL09, ADL11, ADL12, ADL14, ADL15, ADL17, ADL18, AEC02, AEC03, AEC05, AEC06, AEC08, AEC09, AEC11, AEC12, AEC14, AEC15, AEC17, AEC18, HBA01, HBA02, HBA03, PDM02, PDM03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DA_EC_SIS_2016.csv</td>\n",
       "      <td>Clave_Entidad, Entidad, Clave_Municipio, Municipio, CLUES, Nombre_CLUES, Mes, Anio, ADM02, ADM03, ADM05, ADM06, ADM08, ADM09, ADM11, ADM12, ADM14, ADM15, ADM17, ADM18, AHA02, AHA03, AHA05, AHA06, AHA08, AHA09, AHA11, AHA12, AHA14, AHA15, AHA17, AHA18, AOB02, AOB03, AOB05, AOB06, AOB08, AOB09, AOB11, AOB12, AOB14, AOB15, AOB17, AOB18, ADL02, ADL03, ADL05, ADL06, ADL08, ADL09, ADL11, ADL12, ADL14, ADL15, ADL17, ADL18, AEC02, AEC03, AEC05, AEC06, AEC08, AEC09, AEC11, AEC12, AEC14, AEC15, AEC17, AEC18, FRS01, FRS02, FRS03, FRS04, HBA01, HBA02, HBA03, PMA01, PDM02, PDM03, RUN01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DA_EC_SIS_2017.csv</td>\n",
       "      <td>Clave_Entidad, Entidad, Clave_Municipio, Municipio, CLUES, Nombre_CLUES, Mes, Anio, ADM02, ADM03, ADM05, ADM06, ADM08, ADM09, ADM11, ADM12, ADM14, ADM15, ADM17, ADM18, AHA02, AHA03, AHA05, AHA06, AHA08, AHA09, AHA11, AHA12, AHA14, AHA15, AHA17, AHA18, AOB02, AOB03, AOB05, AOB06, AOB08, AOB09, AOB11, AOB12, AOB14, AOB15, AOB17, AOB18, ADL02, ADL03, ADL05, ADL06, ADL08, ADL09, ADL11, ADL12, ADL14, ADL15, ADL17, ADL18, AEC02, AEC03, AEC05, AEC06, AEC08, AEC09, AEC11, AEC12, AEC14, AEC15, AEC17, AEC18, FRS01, FRS02, FRS03, FRS04, HBA01, HBA02, HBA03, PMA01, PDM02, PDM03, RUN01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DA_EC_SIS_2018.csv</td>\n",
       "      <td>Clave_Entidad, Entidad, Clave_Municipio, Municipio, CLUES, Nombre_CLUES, Mes, Anio, ADM02, ADM03, ADM05, ADM06, ADM08, ADM09, ADM11, ADM12, ADM14, ADM15, ADM17, ADM18, AHA02, AHA03, AHA05, AHA06, AHA08, AHA09, AHA11, AHA12, AHA14, AHA15, AHA17, AHA18, AOB02, AOB03, AOB05, AOB06, AOB08, AOB09, AOB11, AOB12, AOB14, AOB15, AOB17, AOB18, ADL02, ADL03, ADL05, ADL06, ADL08, ADL09, ADL11, ADL12, ADL14, ADL15, ADL17, ADL18, AEC02, AEC03, AEC05, AEC06, AEC08, AEC09, AEC11, AEC12, AEC14, AEC15, AEC17, AEC18, FRS01, FRS02, FRS03, FRS04, HBA01, HBA02, HBA03, PMA01, PDM02, PDM03, RUN01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DA_EC_SIS_2019.csv</td>\n",
       "      <td>Clave_Entidad, Entidad, Clave_Municipio, Municipio, CLUES, Nombre_CLUES, Mes, Anio, ADM02, ADM03, ADM05, ADM06, ADM08, ADM09, ADM11, ADM12, ADM14, ADM15, ADM17, ADM18, AHA02, AHA03, AHA05, AHA06, AHA08, AHA09, AHA11, AHA12, AHA14, AHA15, AHA17, AHA18, AOB02, AOB03, AOB05, AOB06, AOB08, AOB09, AOB11, AOB12, AOB14, AOB15, AOB17, AOB18, ADL02, ADL03, ADL05, ADL06, ADL08, ADL09, ADL11, ADL12, ADL14, ADL15, ADL17, ADL18, AEC02, AEC03, AEC05, AEC06, AEC08, AEC09, AEC11, AEC12, AEC14, AEC15, AEC17, AEC18, FRS01, FRS02, FRS03, FRS04, HBA01, HBA02, HBA03, PMA01, PDM02, PDM03, RUN01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DA_EC_SIS_2020.csv</td>\n",
       "      <td>Clave_Entidad, Entidad, Clave_Municipio, Municipio, CLUES, Nombre_CLUES, MES, ANIO, ADL02, ADL03, ADL05, ADL06, ADL08, ADL09, ADL11, ADL12, ADL14, ADL15, ADL17, ADL18, ADM02, ADM03, ADM05, ADM06, ADM08, ADM09, ADM11, ADM12, ADM14, ADM15, ADM17, ADM18, AEC02, AEC03, AEC05, AEC06, AEC08, AEC09, AEC11, AEC12, AEC14, AEC15, AEC17, AEC18, AHA02, AHA03, AHA05, AHA06, AHA08, AHA09, AHA11, AHA12, AHA14, AHA15, AHA17, AHA18, AOB02, AOB03, AOB05, AOB06, AOB08, AOB09, AOB11, AOB12, AOB14, AOB15, AOB17, AOB18, FRS01, FRS02, FRS03, FRS04, HBA01, HBA02, HBA03, PDM02, PDM03, PMA01, RUN01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DA_EC_SIS_2021.csv</td>\n",
       "      <td>CLAVE_ENTIDAD, ENTIDAD, CLAVE_MUNICIPIO, MUNICIPIO, CLUES, NOMBRE_CLUES, MES, ANIO, ADL02, ADL03, ADL05, ADL06, ADL08, ADL09, ADL11, ADL12, ADL14, ADL15, ADL17, ADL18, ADM02, ADM03, ADM05, ADM06, ADM08, ADM09, ADM11, ADM12, ADM14, ADM15, ADM17, ADM18, ADM19, ADM20, ADM21, ADM22, ADM23, AEC02, AEC03, AEC05, AEC06, AEC08, AEC09, AEC11, AEC12, AEC14, AEC15, AEC17, AEC18, AHA02, AHA03, AHA05, AHA06, AHA08, AHA09, AHA11, AHA12, AHA14, AHA15, AHA17, AHA18, AOB02, AOB03, AOB05, AOB06, AOB08, AOB09, AOB11, AOB12, AOB14, AOB15, AOB17, AOB18, FRS01, FRS02, FRS03, FRS04, HBA01, HBA02, HBA03, PDM02, PDM03, PMA01, PMA02, RUN01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DA_EC_SIS_2022.csv</td>\n",
       "      <td>CLAVE_ENTIDAD, ENTIDAD, CLAVE_MUNICIPIO, MUNICIPIO, CLUES, NOMBRE_CLUES, MES, ANIO, ADL02, ADL03, ADL05, ADL06, ADL08, ADL09, ADL11, ADL12, ADL14, ADL15, ADL17, ADL18, ADM02, ADM03, ADM05, ADM06, ADM08, ADM09, ADM11, ADM12, ADM14, ADM15, ADM17, ADM18, ADM19, ADM20, ADM21, ADM22, ADM23, AEC02, AEC03, AEC05, AEC06, AEC08, AEC09, AEC11, AEC12, AEC14, AEC15, AEC17, AEC18, AHA02, AHA03, AHA05, AHA06, AHA08, AHA09, AHA11, AHA12, AHA14, AHA15, AHA17, AHA18, AOB02, AOB03, AOB05, AOB06, AOB08, AOB09, AOB11, AOB12, AOB14, AOB15, AOB17, AOB18, FRS01, FRS02, FRS03, FRS04, HBA01, HBA02, HBA03, PDM02, PDM03, PMA01, PMA02, RUN01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DA_EC_SIS_2023.csv</td>\n",
       "      <td>CLAVE_ENTIDAD, ENTIDAD, CLAVE_MUNICIPIO, MUNICIPIO, CLUES, NOMBRE_CLUES, MES, ANIO, ADL02, ADL03, ADL05, ADL06, ADL08, ADL09, ADL11, ADL12, ADL14, ADL15, ADL17, ADL18, ADM02, ADM03, ADM05, ADM06, ADM08, ADM09, ADM11, ADM12, ADM14, ADM15, ADM17, ADM18, ADM19, ADM20, ADM21, ADM22, ADM23, AEC02, AEC03, AEC05, AEC06, AEC08, AEC09, AEC11, AEC12, AEC14, AEC15, AEC17, AEC18, AHA02, AHA03, AHA05, AHA06, AHA08, AHA09, AHA11, AHA12, AHA14, AHA15, AHA17, AHA18, AOB02, AOB03, AOB05, AOB06, AOB08, AOB09, AOB11, AOB12, AOB14, AOB15, AOB17, AOB18, FRS01, FRS02, FRS03, FRS04, HBA01, HBA02, HBA03, PDM02, PDM03, PMA01, PMA02, RUN01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Archivo  \\\n",
       "0   DA_EC_SIS_2010.csv   \n",
       "1   DA_EC_SIS_2011.csv   \n",
       "2   DA_EC_SIS_2012.csv   \n",
       "3   DA_EC_SIS_2013.csv   \n",
       "4   DA_EC_SIS_2014.csv   \n",
       "5   DA_EC_SIS_2015.csv   \n",
       "6   DA_EC_SIS_2016.csv   \n",
       "7   DA_EC_SIS_2017.csv   \n",
       "8   DA_EC_SIS_2018.csv   \n",
       "9   DA_EC_SIS_2019.csv   \n",
       "10  DA_EC_SIS_2020.csv   \n",
       "11  DA_EC_SIS_2021.csv   \n",
       "12  DA_EC_SIS_2022.csv   \n",
       "13  DA_EC_SIS_2023.csv   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Columnas  \n",
       "0                                                                                                                   Clave_Entidad, Entidad, Clave_Municipio, Municipio, CLUES, Nombre_CLUES, Mes, Anio, ADM02, ADM03, ADM05, ADM06, ADM08, ADM09, ADM11, ADM12, ADM14, ADM15, ADM17, ADM18, AHA02, AHA03, AHA05, AHA06, AHA08, AHA09, AHA11, AHA12, AHA14, AHA15, AHA17, AHA18, AOB02, AOB03, AOB05, AOB06, AOB08, AOB09, AOB11, AOB12, AOB14, AOB15, AOB17, AOB18, ADL02, ADL03, ADL05, ADL06, ADL08, ADL09, ADL11, ADL12, ADL14, ADL15, ADL17, ADL18, AEC02, AEC03, AEC05, AEC06, AEC08, AEC09, AEC11, AEC12, AEC14, AEC15, AEC17, AEC18, PDM01  \n",
       "1                                                                                                                   Clave_Entidad, Entidad, Clave_Municipio, Municipio, CLUES, Nombre_CLUES, Mes, Anio, ADM02, ADM03, ADM05, ADM06, ADM08, ADM09, ADM11, ADM12, ADM14, ADM15, ADM17, ADM18, AHA02, AHA03, AHA05, AHA06, AHA08, AHA09, AHA11, AHA12, AHA14, AHA15, AHA17, AHA18, AOB02, AOB03, AOB05, AOB06, AOB08, AOB09, AOB11, AOB12, AOB14, AOB15, AOB17, AOB18, ADL02, ADL03, ADL05, ADL06, ADL08, ADL09, ADL11, ADL12, ADL14, ADL15, ADL17, ADL18, AEC02, AEC03, AEC05, AEC06, AEC08, AEC09, AEC11, AEC12, AEC14, AEC15, AEC17, AEC18, PDM01  \n",
       "2                                                                                                                   Clave_Entidad, Entidad, Clave_Municipio, Municipio, CLUES, Nombre_CLUES, Mes, Anio, ADM02, ADM03, ADM05, ADM06, ADM08, ADM09, ADM11, ADM12, ADM14, ADM15, ADM17, ADM18, AHA02, AHA03, AHA05, AHA06, AHA08, AHA09, AHA11, AHA12, AHA14, AHA15, AHA17, AHA18, AOB02, AOB03, AOB05, AOB06, AOB08, AOB09, AOB11, AOB12, AOB14, AOB15, AOB17, AOB18, ADL02, ADL03, ADL05, ADL06, ADL08, ADL09, ADL11, ADL12, ADL14, ADL15, ADL17, ADL18, AEC02, AEC03, AEC05, AEC06, AEC08, AEC09, AEC11, AEC12, AEC14, AEC15, AEC17, AEC18, PDM01  \n",
       "3                                                                                                     Clave_Entidad, Entidad, Clave_Municipio, Municipio, CLUES, Nombre_CLUES, Mes, Anio, ADM02, ADM03, ADM05, ADM06, ADM08, ADM09, ADM11, ADM12, ADM14, ADM15, ADM17, ADM18, AHA02, AHA03, AHA05, AHA06, AHA08, AHA09, AHA11, AHA12, AHA14, AHA15, AHA17, AHA18, AOB02, AOB03, AOB05, AOB06, AOB08, AOB09, AOB11, AOB12, AOB14, AOB15, AOB17, AOB18, ADL02, ADL03, ADL05, ADL06, ADL08, ADL09, ADL11, ADL12, ADL14, ADL15, ADL17, ADL18, AEC02, AEC03, AEC05, AEC06, AEC08, AEC09, AEC11, AEC12, AEC14, AEC15, AEC17, AEC18, PDM01, RHP01, RHP02  \n",
       "4                                                                                                     Clave_Entidad, Entidad, Clave_Municipio, Municipio, CLUES, Nombre_CLUES, Mes, Anio, ADM02, ADM03, ADM05, ADM06, ADM08, ADM09, ADM11, ADM12, ADM14, ADM15, ADM17, ADM18, AHA02, AHA03, AHA05, AHA06, AHA08, AHA09, AHA11, AHA12, AHA14, AHA15, AHA17, AHA18, AOB02, AOB03, AOB05, AOB06, AOB08, AOB09, AOB11, AOB12, AOB14, AOB15, AOB17, AOB18, ADL02, ADL03, ADL05, ADL06, ADL08, ADL09, ADL11, ADL12, ADL14, ADL15, ADL17, ADL18, AEC02, AEC03, AEC05, AEC06, AEC08, AEC09, AEC11, AEC12, AEC14, AEC15, AEC17, AEC18, PDM01, RHP01, RHP02  \n",
       "5                                                                                       Clave_Entidad, Entidad, Clave_Municipio, Municipio, CLUES, Nombre_CLUES, Mes, Anio, ADM02, ADM03, ADM05, ADM06, ADM08, ADM09, ADM11, ADM12, ADM14, ADM15, ADM17, ADM18, AHA02, AHA03, AHA05, AHA06, AHA08, AHA09, AHA11, AHA12, AHA14, AHA15, AHA17, AHA18, AOB02, AOB03, AOB05, AOB06, AOB08, AOB09, AOB11, AOB12, AOB14, AOB15, AOB17, AOB18, ADL02, ADL03, ADL05, ADL06, ADL08, ADL09, ADL11, ADL12, ADL14, ADL15, ADL17, ADL18, AEC02, AEC03, AEC05, AEC06, AEC08, AEC09, AEC11, AEC12, AEC14, AEC15, AEC17, AEC18, HBA01, HBA02, HBA03, PDM02, PDM03  \n",
       "6                                             Clave_Entidad, Entidad, Clave_Municipio, Municipio, CLUES, Nombre_CLUES, Mes, Anio, ADM02, ADM03, ADM05, ADM06, ADM08, ADM09, ADM11, ADM12, ADM14, ADM15, ADM17, ADM18, AHA02, AHA03, AHA05, AHA06, AHA08, AHA09, AHA11, AHA12, AHA14, AHA15, AHA17, AHA18, AOB02, AOB03, AOB05, AOB06, AOB08, AOB09, AOB11, AOB12, AOB14, AOB15, AOB17, AOB18, ADL02, ADL03, ADL05, ADL06, ADL08, ADL09, ADL11, ADL12, ADL14, ADL15, ADL17, ADL18, AEC02, AEC03, AEC05, AEC06, AEC08, AEC09, AEC11, AEC12, AEC14, AEC15, AEC17, AEC18, FRS01, FRS02, FRS03, FRS04, HBA01, HBA02, HBA03, PMA01, PDM02, PDM03, RUN01  \n",
       "7                                             Clave_Entidad, Entidad, Clave_Municipio, Municipio, CLUES, Nombre_CLUES, Mes, Anio, ADM02, ADM03, ADM05, ADM06, ADM08, ADM09, ADM11, ADM12, ADM14, ADM15, ADM17, ADM18, AHA02, AHA03, AHA05, AHA06, AHA08, AHA09, AHA11, AHA12, AHA14, AHA15, AHA17, AHA18, AOB02, AOB03, AOB05, AOB06, AOB08, AOB09, AOB11, AOB12, AOB14, AOB15, AOB17, AOB18, ADL02, ADL03, ADL05, ADL06, ADL08, ADL09, ADL11, ADL12, ADL14, ADL15, ADL17, ADL18, AEC02, AEC03, AEC05, AEC06, AEC08, AEC09, AEC11, AEC12, AEC14, AEC15, AEC17, AEC18, FRS01, FRS02, FRS03, FRS04, HBA01, HBA02, HBA03, PMA01, PDM02, PDM03, RUN01  \n",
       "8                                             Clave_Entidad, Entidad, Clave_Municipio, Municipio, CLUES, Nombre_CLUES, Mes, Anio, ADM02, ADM03, ADM05, ADM06, ADM08, ADM09, ADM11, ADM12, ADM14, ADM15, ADM17, ADM18, AHA02, AHA03, AHA05, AHA06, AHA08, AHA09, AHA11, AHA12, AHA14, AHA15, AHA17, AHA18, AOB02, AOB03, AOB05, AOB06, AOB08, AOB09, AOB11, AOB12, AOB14, AOB15, AOB17, AOB18, ADL02, ADL03, ADL05, ADL06, ADL08, ADL09, ADL11, ADL12, ADL14, ADL15, ADL17, ADL18, AEC02, AEC03, AEC05, AEC06, AEC08, AEC09, AEC11, AEC12, AEC14, AEC15, AEC17, AEC18, FRS01, FRS02, FRS03, FRS04, HBA01, HBA02, HBA03, PMA01, PDM02, PDM03, RUN01  \n",
       "9                                             Clave_Entidad, Entidad, Clave_Municipio, Municipio, CLUES, Nombre_CLUES, Mes, Anio, ADM02, ADM03, ADM05, ADM06, ADM08, ADM09, ADM11, ADM12, ADM14, ADM15, ADM17, ADM18, AHA02, AHA03, AHA05, AHA06, AHA08, AHA09, AHA11, AHA12, AHA14, AHA15, AHA17, AHA18, AOB02, AOB03, AOB05, AOB06, AOB08, AOB09, AOB11, AOB12, AOB14, AOB15, AOB17, AOB18, ADL02, ADL03, ADL05, ADL06, ADL08, ADL09, ADL11, ADL12, ADL14, ADL15, ADL17, ADL18, AEC02, AEC03, AEC05, AEC06, AEC08, AEC09, AEC11, AEC12, AEC14, AEC15, AEC17, AEC18, FRS01, FRS02, FRS03, FRS04, HBA01, HBA02, HBA03, PMA01, PDM02, PDM03, RUN01  \n",
       "10                                            Clave_Entidad, Entidad, Clave_Municipio, Municipio, CLUES, Nombre_CLUES, MES, ANIO, ADL02, ADL03, ADL05, ADL06, ADL08, ADL09, ADL11, ADL12, ADL14, ADL15, ADL17, ADL18, ADM02, ADM03, ADM05, ADM06, ADM08, ADM09, ADM11, ADM12, ADM14, ADM15, ADM17, ADM18, AEC02, AEC03, AEC05, AEC06, AEC08, AEC09, AEC11, AEC12, AEC14, AEC15, AEC17, AEC18, AHA02, AHA03, AHA05, AHA06, AHA08, AHA09, AHA11, AHA12, AHA14, AHA15, AHA17, AHA18, AOB02, AOB03, AOB05, AOB06, AOB08, AOB09, AOB11, AOB12, AOB14, AOB15, AOB17, AOB18, FRS01, FRS02, FRS03, FRS04, HBA01, HBA02, HBA03, PDM02, PDM03, PMA01, RUN01  \n",
       "11  CLAVE_ENTIDAD, ENTIDAD, CLAVE_MUNICIPIO, MUNICIPIO, CLUES, NOMBRE_CLUES, MES, ANIO, ADL02, ADL03, ADL05, ADL06, ADL08, ADL09, ADL11, ADL12, ADL14, ADL15, ADL17, ADL18, ADM02, ADM03, ADM05, ADM06, ADM08, ADM09, ADM11, ADM12, ADM14, ADM15, ADM17, ADM18, ADM19, ADM20, ADM21, ADM22, ADM23, AEC02, AEC03, AEC05, AEC06, AEC08, AEC09, AEC11, AEC12, AEC14, AEC15, AEC17, AEC18, AHA02, AHA03, AHA05, AHA06, AHA08, AHA09, AHA11, AHA12, AHA14, AHA15, AHA17, AHA18, AOB02, AOB03, AOB05, AOB06, AOB08, AOB09, AOB11, AOB12, AOB14, AOB15, AOB17, AOB18, FRS01, FRS02, FRS03, FRS04, HBA01, HBA02, HBA03, PDM02, PDM03, PMA01, PMA02, RUN01  \n",
       "12  CLAVE_ENTIDAD, ENTIDAD, CLAVE_MUNICIPIO, MUNICIPIO, CLUES, NOMBRE_CLUES, MES, ANIO, ADL02, ADL03, ADL05, ADL06, ADL08, ADL09, ADL11, ADL12, ADL14, ADL15, ADL17, ADL18, ADM02, ADM03, ADM05, ADM06, ADM08, ADM09, ADM11, ADM12, ADM14, ADM15, ADM17, ADM18, ADM19, ADM20, ADM21, ADM22, ADM23, AEC02, AEC03, AEC05, AEC06, AEC08, AEC09, AEC11, AEC12, AEC14, AEC15, AEC17, AEC18, AHA02, AHA03, AHA05, AHA06, AHA08, AHA09, AHA11, AHA12, AHA14, AHA15, AHA17, AHA18, AOB02, AOB03, AOB05, AOB06, AOB08, AOB09, AOB11, AOB12, AOB14, AOB15, AOB17, AOB18, FRS01, FRS02, FRS03, FRS04, HBA01, HBA02, HBA03, PDM02, PDM03, PMA01, PMA02, RUN01  \n",
       "13  CLAVE_ENTIDAD, ENTIDAD, CLAVE_MUNICIPIO, MUNICIPIO, CLUES, NOMBRE_CLUES, MES, ANIO, ADL02, ADL03, ADL05, ADL06, ADL08, ADL09, ADL11, ADL12, ADL14, ADL15, ADL17, ADL18, ADM02, ADM03, ADM05, ADM06, ADM08, ADM09, ADM11, ADM12, ADM14, ADM15, ADM17, ADM18, ADM19, ADM20, ADM21, ADM22, ADM23, AEC02, AEC03, AEC05, AEC06, AEC08, AEC09, AEC11, AEC12, AEC14, AEC15, AEC17, AEC18, AHA02, AHA03, AHA05, AHA06, AHA08, AHA09, AHA11, AHA12, AHA14, AHA15, AHA17, AHA18, AOB02, AOB03, AOB05, AOB06, AOB08, AOB09, AOB11, AOB12, AOB14, AOB15, AOB17, AOB18, FRS01, FRS02, FRS03, FRS04, HBA01, HBA02, HBA03, PDM02, PDM03, PMA01, PMA02, RUN01  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a trabajar con los archivos de extensión csv que están en la carpeta \"Bases saludo taller\"\n",
    "1. Dame el codigo para iterar sobre cada archivo csv con el fin de normalizar el nombre de las columnas, de manera que todos los nombres de las columnas estén en mayusculas. Luego normaliza que el orden de las columnas sea tal que siempre estas sean las primeras \"CLAVE_ENTIDAD, ENTIDAD, CLAVE_MUNICIPIO, MUNICIPIO, CLUES, NOMBRE_CLUES, MES, ANIO\" y las restantes se ordenen en orden alfabetico. \n",
    "2. Tambien, alli donde en las columnas encuentrs el texto \"NULL\" cambialo por espacios en blanco. \n",
    "3. Guarda los cambios en un archivo csv que al final tenga en el nombre \"normalizado\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo DA_EC_SIS_2010_normalizado.csv guardado exitosamente.\n",
      "Archivo DA_EC_SIS_2011_normalizado.csv guardado exitosamente.\n",
      "Archivo DA_EC_SIS_2012_normalizado.csv guardado exitosamente.\n",
      "Archivo DA_EC_SIS_2013_normalizado.csv guardado exitosamente.\n",
      "Archivo DA_EC_SIS_2014_normalizado.csv guardado exitosamente.\n",
      "Archivo DA_EC_SIS_2015_normalizado.csv guardado exitosamente.\n",
      "Archivo DA_EC_SIS_2016_normalizado.csv guardado exitosamente.\n",
      "Archivo DA_EC_SIS_2017_normalizado.csv guardado exitosamente.\n",
      "Archivo DA_EC_SIS_2018_normalizado.csv guardado exitosamente.\n",
      "Archivo DA_EC_SIS_2019_normalizado.csv guardado exitosamente.\n",
      "Error al procesar DA_EC_SIS_2020.csv con codificación utf-8: 'utf-8' codec can't decode byte 0xd3 in position 4: invalid continuation byte\n",
      "Archivo DA_EC_SIS_2020_normalizado.csv guardado exitosamente.\n",
      "Error al procesar DA_EC_SIS_2021.csv con codificación utf-8: 'utf-8' codec can't decode byte 0xcd in position 3: invalid continuation byte\n",
      "Archivo DA_EC_SIS_2021_normalizado.csv guardado exitosamente.\n",
      "Error al procesar DA_EC_SIS_2022.csv con codificación utf-8: 'utf-8' codec can't decode byte 0xcd in position 3: invalid continuation byte\n",
      "Archivo DA_EC_SIS_2022_normalizado.csv guardado exitosamente.\n",
      "Error al procesar DA_EC_SIS_2023.csv con codificación utf-8: 'utf-8' codec can't decode byte 0xcd in position 3: invalid continuation byte\n",
      "Archivo DA_EC_SIS_2023_normalizado.csv guardado exitosamente.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directorio donde se encuentran los archivos CSV\n",
    "directory = \"Bases saludo taller\"\n",
    "\n",
    "# Columnas prioritarias para el orden\n",
    "priority_columns = [\"CLAVE_ENTIDAD\", \"ENTIDAD\", \"CLAVE_MUNICIPIO\", \"MUNICIPIO\", \"CLUES\", \"NOMBRE_CLUES\", \"MES\", \"ANIO\"]\n",
    "\n",
    "# Iterar sobre los archivos en el directorio\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "\n",
    "        # Intentar leer con diferentes codificaciones\n",
    "        encodings = [\"utf-8\", \"latin1\", \"iso-8859-1\"]\n",
    "        for encoding in encodings:\n",
    "            try:\n",
    "                # Leer el archivo completo\n",
    "                df = pd.read_csv(file_path, encoding=encoding)\n",
    "\n",
    "                # Normalizar nombres de columnas a mayúsculas\n",
    "                df.columns = [col.upper() for col in df.columns]\n",
    "\n",
    "                # Reemplazar \"NULL\" por espacios en blanco\n",
    "                df.replace(\"NULL\", \"\", inplace=True)\n",
    "\n",
    "                # Asegurar el orden de las columnas\n",
    "                existing_priority = [col for col in priority_columns if col in df.columns]\n",
    "                remaining_columns = sorted([col for col in df.columns if col not in existing_priority])\n",
    "                new_column_order = existing_priority + remaining_columns\n",
    "\n",
    "                df = df[new_column_order]\n",
    "\n",
    "                # Guardar el archivo normalizado\n",
    "                normalized_filename = filename.replace(\".csv\", \"_normalizado.csv\")\n",
    "                normalized_path = os.path.join(directory, normalized_filename)\n",
    "                df.to_csv(normalized_path, index=False, encoding=encoding)\n",
    "\n",
    "                print(f\"Archivo {normalized_filename} guardado exitosamente.\")\n",
    "\n",
    "                break  # Salir del bucle si la lectura fue exitosa\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error al procesar {filename} con codificación {encoding}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora dame el codigo para que, iterando entre los archivos csv que están en la carpeta \"Bases saludo taller\" y cuyo nombre termina en \"_normalizado\", se obtengan las filas duplicadas. Si hay filas duplicadas imprime un mensaje y la ubicación de la fila antes de eliminar los duplicados manteniendo el primero. \n",
    "\n",
    "2. genera un codigo que itere sobre estos archivos y reporte cuantos y cuales tipos de datos contiene cada columna de cada archivo. Me interesa saber si cada columna tiene más de un tipo de dato. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No se encontraron duplicados en DA_EC_SIS_2010_normalizado.csv.\n",
      "No se encontraron duplicados en DA_EC_SIS_2011_normalizado.csv.\n",
      "No se encontraron duplicados en DA_EC_SIS_2012_normalizado.csv.\n",
      "No se encontraron duplicados en DA_EC_SIS_2013_normalizado.csv.\n",
      "No se encontraron duplicados en DA_EC_SIS_2014_normalizado.csv.\n",
      "No se encontraron duplicados en DA_EC_SIS_2015_normalizado.csv.\n",
      "No se encontraron duplicados en DA_EC_SIS_2016_normalizado.csv.\n",
      "No se encontraron duplicados en DA_EC_SIS_2017_normalizado.csv.\n",
      "No se encontraron duplicados en DA_EC_SIS_2018_normalizado.csv.\n",
      "No se encontraron duplicados en DA_EC_SIS_2019_normalizado.csv.\n",
      "Error al procesar DA_EC_SIS_2020_normalizado.csv con codificación utf-8: 'utf-8' codec can't decode byte 0xc9 in position 11: invalid continuation byte\n",
      "No se encontraron duplicados en DA_EC_SIS_2020_normalizado.csv.\n",
      "Error al procesar DA_EC_SIS_2021_normalizado.csv con codificación utf-8: 'utf-8' codec can't decode byte 0xc9 in position 11: invalid continuation byte\n",
      "No se encontraron duplicados en DA_EC_SIS_2021_normalizado.csv.\n",
      "Error al procesar DA_EC_SIS_2022_normalizado.csv con codificación utf-8: 'utf-8' codec can't decode byte 0xc9 in position 11: invalid continuation byte\n",
      "No se encontraron duplicados en DA_EC_SIS_2022_normalizado.csv.\n",
      "Error al procesar DA_EC_SIS_2023_normalizado.csv con codificación utf-8: 'utf-8' codec can't decode byte 0xc9 in position 11: invalid continuation byte\n",
      "No se encontraron duplicados en DA_EC_SIS_2023_normalizado.csv.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directorio donde se encuentran los archivos CSV\n",
    "directory = \"Bases saludo taller\"\n",
    "\n",
    "# Codificaciones a intentar\n",
    "encodings = [\"utf-8\", \"latin1\", \"iso-8859-1\"]\n",
    "\n",
    "# Iterar sobre los archivos normalizados\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\"_normalizado.csv\"):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        processed = False  # Bandera para verificar si el archivo se procesó correctamente\n",
    "\n",
    "        for encoding in encodings:\n",
    "            try:\n",
    "                # Leer el archivo con diferentes codificaciones\n",
    "                df = pd.read_csv(file_path, encoding=encoding, low_memory=False)\n",
    "\n",
    "                # Verificar filas duplicadas\n",
    "                duplicated_rows = df[df.duplicated(keep=False)]\n",
    "\n",
    "                if not duplicated_rows.empty:\n",
    "                    print(f\"\\nDuplicados encontrados en {filename}:\")\n",
    "                    # Obtener las ubicaciones (índices) de las filas duplicadas\n",
    "                    duplicate_indices = duplicated_rows.index.tolist()\n",
    "                    print(f\"Índices de filas duplicadas: {duplicate_indices}\")\n",
    "\n",
    "                    # Mostrar las filas duplicadas\n",
    "                    print(duplicated_rows)\n",
    "\n",
    "                    # Eliminar duplicados manteniendo la primera aparición\n",
    "                    df = df.drop_duplicates(keep='first')\n",
    "\n",
    "                    # Guardar el archivo sin duplicados\n",
    "                    df.to_csv(file_path, index=False, encoding=encoding)\n",
    "                    print(f\"Duplicados eliminados en {filename}. Archivo actualizado guardado.\")\n",
    "\n",
    "                else:\n",
    "                    print(f\"No se encontraron duplicados en {filename}.\")\n",
    "\n",
    "                processed = True  # Marcar como procesado correctamente\n",
    "                break  # Salir del bucle si la lectura fue exitosa\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error al procesar {filename} con codificación {encoding}: {e}\")\n",
    "                continue  # Probar con la siguiente codificación\n",
    "\n",
    "        if not processed:\n",
    "            print(f\"No se pudo procesar {filename} con ninguna de las codificaciones.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "identificar tipos de valores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Análisis de tipos de datos en DA_EC_SIS_2010_normalizado.csv (codificación: utf-8):\n",
      "  - Columna 'CLAVE_ENTIDAD' tiene un solo tipo de dato: int\n",
      "  - Columna 'ENTIDAD' tiene un solo tipo de dato: str\n",
      "  - Columna 'CLAVE_MUNICIPIO' tiene un solo tipo de dato: int\n",
      "  - Columna 'MUNICIPIO' tiene un solo tipo de dato: str\n",
      "  - Columna 'CLUES' tiene un solo tipo de dato: str\n",
      "  - Columna 'NOMBRE_CLUES' tiene un solo tipo de dato: str\n",
      "  - Columna 'MES' tiene un solo tipo de dato: int\n",
      "  - Columna 'ANIO' tiene un solo tipo de dato: int\n",
      "  - Columna 'ADL02' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL03' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL05' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL06' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL08' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL09' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL11' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL12' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL14' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL15' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL17' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL18' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM02' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM03' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM05' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM06' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM08' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM09' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM11' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM12' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM14' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM15' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM17' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM18' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC02' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC03' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC05' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC06' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC08' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC09' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC11' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC12' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC14' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC15' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC17' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC18' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA02' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA03' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA05' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA06' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA08' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA09' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA11' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA12' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA14' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA15' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA17' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA18' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB02' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB03' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB05' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB06' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB08' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB09' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB11' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB12' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB14' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB15' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB17' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB18' tiene un solo tipo de dato: float\n",
      "  - Columna 'PDM01' tiene un solo tipo de dato: float\n",
      "\n",
      "Análisis de tipos de datos en DA_EC_SIS_2011_normalizado.csv (codificación: utf-8):\n",
      "  - Columna 'CLAVE_ENTIDAD' tiene un solo tipo de dato: int\n",
      "  - Columna 'ENTIDAD' tiene un solo tipo de dato: str\n",
      "  - Columna 'CLAVE_MUNICIPIO' tiene un solo tipo de dato: int\n",
      "  - Columna 'MUNICIPIO' tiene un solo tipo de dato: str\n",
      "  - Columna 'CLUES' tiene un solo tipo de dato: str\n",
      "  - Columna 'NOMBRE_CLUES' tiene un solo tipo de dato: str\n",
      "  - Columna 'MES' tiene un solo tipo de dato: int\n",
      "  - Columna 'ANIO' tiene un solo tipo de dato: int\n",
      "  - Columna 'ADL02' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL03' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL05' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL06' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL08' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL09' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL11' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL12' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL14' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL15' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL17' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL18' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM02' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM03' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM05' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM06' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM08' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM09' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM11' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM12' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM14' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM15' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM17' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM18' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC02' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC03' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC05' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC06' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC08' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC09' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC11' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC12' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC14' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC15' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC17' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC18' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA02' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA03' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA05' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA06' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA08' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA09' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA11' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA12' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA14' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA15' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA17' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA18' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB02' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB03' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB05' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB06' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB08' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB09' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB11' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB12' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB14' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB15' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB17' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB18' tiene un solo tipo de dato: float\n",
      "  - Columna 'PDM01' tiene un solo tipo de dato: float\n",
      "\n",
      "Análisis de tipos de datos en DA_EC_SIS_2012_normalizado.csv (codificación: utf-8):\n",
      "  - Columna 'CLAVE_ENTIDAD' tiene un solo tipo de dato: int\n",
      "  - Columna 'ENTIDAD' tiene un solo tipo de dato: str\n",
      "  - Columna 'CLAVE_MUNICIPIO' tiene un solo tipo de dato: int\n",
      "  - Columna 'MUNICIPIO' tiene un solo tipo de dato: str\n",
      "  - Columna 'CLUES' tiene un solo tipo de dato: str\n",
      "  - Columna 'NOMBRE_CLUES' tiene un solo tipo de dato: str\n",
      "  - Columna 'MES' tiene un solo tipo de dato: int\n",
      "  - Columna 'ANIO' tiene un solo tipo de dato: int\n",
      "  - Columna 'ADL02' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL03' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL05' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL06' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL08' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL09' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL11' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL12' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL14' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL15' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL17' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL18' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM02' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM03' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM05' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM06' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM08' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM09' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM11' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM12' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM14' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM15' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM17' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM18' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC02' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC03' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC05' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC06' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC08' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC09' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC11' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC12' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC14' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC15' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC17' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC18' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA02' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA03' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA05' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA06' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA08' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA09' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA11' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA12' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA14' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA15' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA17' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA18' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB02' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB03' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB05' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB06' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB08' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB09' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB11' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB12' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB14' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB15' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB17' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB18' tiene un solo tipo de dato: float\n",
      "  - Columna 'PDM01' tiene un solo tipo de dato: float\n",
      "\n",
      "Análisis de tipos de datos en DA_EC_SIS_2013_normalizado.csv (codificación: utf-8):\n",
      "  - Columna 'CLAVE_ENTIDAD' tiene un solo tipo de dato: int\n",
      "  - Columna 'ENTIDAD' tiene un solo tipo de dato: str\n",
      "  - Columna 'CLAVE_MUNICIPIO' tiene un solo tipo de dato: int\n",
      "  - Columna 'MUNICIPIO' tiene un solo tipo de dato: str\n",
      "  - Columna 'CLUES' tiene un solo tipo de dato: str\n",
      "  - Columna 'NOMBRE_CLUES' tiene un solo tipo de dato: str\n",
      "  - Columna 'MES' tiene un solo tipo de dato: int\n",
      "  - Columna 'ANIO' tiene un solo tipo de dato: int\n",
      "  - Columna 'ADL02' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL03' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL05' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL06' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL08' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL09' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL11' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL12' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL14' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL15' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL17' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL18' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM02' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM03' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM05' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM06' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM08' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM09' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM11' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM12' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM14' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM15' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM17' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM18' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC02' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC03' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC05' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC06' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC08' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC09' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC11' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC12' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC14' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC15' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC17' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC18' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA02' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA03' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA05' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA06' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA08' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA09' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA11' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA12' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA14' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA15' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA17' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA18' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB02' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB03' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB05' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB06' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB08' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB09' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB11' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB12' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB14' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB15' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB17' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB18' tiene un solo tipo de dato: float\n",
      "  - Columna 'PDM01' tiene un solo tipo de dato: float\n",
      "  - Columna 'RHP01' tiene un solo tipo de dato: float\n",
      "  - Columna 'RHP02' tiene un solo tipo de dato: float\n",
      "\n",
      "Análisis de tipos de datos en DA_EC_SIS_2014_normalizado.csv (codificación: utf-8):\n",
      "  - Columna 'CLAVE_ENTIDAD' tiene un solo tipo de dato: int\n",
      "  - Columna 'ENTIDAD' tiene un solo tipo de dato: str\n",
      "  - Columna 'CLAVE_MUNICIPIO' tiene un solo tipo de dato: int\n",
      "  - Columna 'MUNICIPIO' tiene un solo tipo de dato: str\n",
      "  - Columna 'CLUES' tiene un solo tipo de dato: str\n",
      "  - Columna 'NOMBRE_CLUES' tiene un solo tipo de dato: str\n",
      "  - Columna 'MES' tiene un solo tipo de dato: int\n",
      "  - Columna 'ANIO' tiene un solo tipo de dato: int\n",
      "  - Columna 'ADL02' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL03' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL05' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL06' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL08' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL09' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL11' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL12' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL14' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL15' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL17' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL18' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM02' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM03' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM05' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM06' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM08' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM09' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM11' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM12' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM14' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM15' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM17' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM18' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC02' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC03' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC05' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC06' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC08' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC09' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC11' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC12' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC14' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC15' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC17' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC18' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA02' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA03' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA05' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA06' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA08' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA09' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA11' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA12' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA14' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA15' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA17' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA18' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB02' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB03' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB05' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB06' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB08' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB09' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB11' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB12' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB14' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB15' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB17' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB18' tiene un solo tipo de dato: float\n",
      "  - Columna 'PDM01' tiene un solo tipo de dato: float\n",
      "  - Columna 'RHP01' tiene un solo tipo de dato: float\n",
      "  - Columna 'RHP02' tiene un solo tipo de dato: float\n",
      "\n",
      "Análisis de tipos de datos en DA_EC_SIS_2015_normalizado.csv (codificación: utf-8):\n",
      "  - Columna 'CLAVE_ENTIDAD' tiene un solo tipo de dato: int\n",
      "  - Columna 'ENTIDAD' tiene un solo tipo de dato: str\n",
      "  - Columna 'CLAVE_MUNICIPIO' tiene un solo tipo de dato: int\n",
      "  - Columna 'MUNICIPIO' tiene un solo tipo de dato: str\n",
      "  - Columna 'CLUES' tiene un solo tipo de dato: str\n",
      "  - Columna 'NOMBRE_CLUES' tiene un solo tipo de dato: str\n",
      "  - Columna 'MES' tiene un solo tipo de dato: int\n",
      "  - Columna 'ANIO' tiene un solo tipo de dato: int\n",
      "  - Columna 'ADL02' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL03' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL05' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL06' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL08' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL09' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL11' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL12' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL14' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL15' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL17' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL18' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM02' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM03' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM05' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM06' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM08' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM09' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM11' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM12' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM14' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM15' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM17' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM18' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC02' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC03' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC05' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC06' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC08' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC09' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC11' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC12' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC14' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC15' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC17' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC18' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA02' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA03' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA05' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA06' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA08' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA09' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA11' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA12' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA14' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA15' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA17' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA18' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB02' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB03' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB05' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB06' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB08' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB09' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB11' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB12' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB14' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB15' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB17' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB18' tiene un solo tipo de dato: float\n",
      "  - Columna 'HBA01' tiene un solo tipo de dato: float\n",
      "  - Columna 'HBA02' tiene un solo tipo de dato: float\n",
      "  - Columna 'HBA03' tiene un solo tipo de dato: float\n",
      "  - Columna 'PDM02' tiene un solo tipo de dato: float\n",
      "  - Columna 'PDM03' tiene un solo tipo de dato: float\n",
      "\n",
      "Análisis de tipos de datos en DA_EC_SIS_2016_normalizado.csv (codificación: utf-8):\n",
      "  - Columna 'CLAVE_ENTIDAD' tiene un solo tipo de dato: int\n",
      "  - Columna 'ENTIDAD' tiene un solo tipo de dato: str\n",
      "  - Columna 'CLAVE_MUNICIPIO' tiene un solo tipo de dato: int\n",
      "  - Columna 'MUNICIPIO' tiene un solo tipo de dato: str\n",
      "  - Columna 'CLUES' tiene un solo tipo de dato: str\n",
      "  - Columna 'NOMBRE_CLUES' tiene un solo tipo de dato: str\n",
      "  - Columna 'MES' tiene un solo tipo de dato: int\n",
      "  - Columna 'ANIO' tiene un solo tipo de dato: int\n",
      "  - Columna 'ADL02' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL03' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL05' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL06' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL08' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL09' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL11' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL12' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL14' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL15' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL17' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL18' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM02' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM03' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM05' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM06' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM08' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM09' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM11' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM12' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM14' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM15' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM17' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM18' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC02' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC03' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC05' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC06' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC08' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC09' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC11' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC12' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC14' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC15' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC17' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC18' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA02' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA03' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA05' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA06' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA08' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA09' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA11' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA12' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA14' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA15' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA17' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA18' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB02' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB03' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB05' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB06' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB08' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB09' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB11' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB12' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB14' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB15' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB17' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB18' tiene un solo tipo de dato: float\n",
      "  - Columna 'FRS01' tiene un solo tipo de dato: float\n",
      "  - Columna 'FRS02' tiene un solo tipo de dato: float\n",
      "  - Columna 'FRS03' tiene un solo tipo de dato: float\n",
      "  - Columna 'FRS04' tiene un solo tipo de dato: float\n",
      "  - Columna 'HBA01' tiene un solo tipo de dato: float\n",
      "  - Columna 'HBA02' tiene un solo tipo de dato: float\n",
      "  - Columna 'HBA03' tiene un solo tipo de dato: float\n",
      "  - Columna 'PDM02' tiene un solo tipo de dato: float\n",
      "  - Columna 'PDM03' tiene un solo tipo de dato: float\n",
      "  - Columna 'PMA01' tiene un solo tipo de dato: float\n",
      "  - Columna 'RUN01' tiene un solo tipo de dato: float\n",
      "\n",
      "Análisis de tipos de datos en DA_EC_SIS_2017_normalizado.csv (codificación: utf-8):\n",
      "  - Columna 'CLAVE_ENTIDAD' tiene un solo tipo de dato: int\n",
      "  - Columna 'ENTIDAD' tiene un solo tipo de dato: str\n",
      "  - Columna 'CLAVE_MUNICIPIO' tiene un solo tipo de dato: int\n",
      "  - Columna 'MUNICIPIO' tiene un solo tipo de dato: str\n",
      "  - Columna 'CLUES' tiene un solo tipo de dato: str\n",
      "  - Columna 'NOMBRE_CLUES' tiene un solo tipo de dato: str\n",
      "  - Columna 'MES' tiene un solo tipo de dato: int\n",
      "  - Columna 'ANIO' tiene un solo tipo de dato: int\n",
      "  - Columna 'ADL02' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL03' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL05' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL06' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL08' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL09' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL11' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL12' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL14' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL15' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL17' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL18' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM02' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM03' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM05' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM06' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM08' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM09' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM11' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM12' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM14' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM15' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM17' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM18' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC02' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC03' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC05' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC06' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC08' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC09' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC11' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC12' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC14' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC15' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC17' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC18' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA02' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA03' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA05' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA06' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA08' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA09' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA11' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA12' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA14' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA15' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA17' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA18' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB02' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB03' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB05' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB06' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB08' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB09' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB11' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB12' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB14' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB15' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB17' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB18' tiene un solo tipo de dato: float\n",
      "  - Columna 'FRS01' tiene un solo tipo de dato: float\n",
      "  - Columna 'FRS02' tiene un solo tipo de dato: float\n",
      "  - Columna 'FRS03' tiene un solo tipo de dato: float\n",
      "  - Columna 'FRS04' tiene un solo tipo de dato: float\n",
      "  - Columna 'HBA01' tiene un solo tipo de dato: float\n",
      "  - Columna 'HBA02' tiene un solo tipo de dato: float\n",
      "  - Columna 'HBA03' tiene un solo tipo de dato: float\n",
      "  - Columna 'PDM02' tiene un solo tipo de dato: float\n",
      "  - Columna 'PDM03' tiene un solo tipo de dato: float\n",
      "  - Columna 'PMA01' tiene un solo tipo de dato: float\n",
      "  - Columna 'RUN01' tiene un solo tipo de dato: float\n",
      "\n",
      "Análisis de tipos de datos en DA_EC_SIS_2018_normalizado.csv (codificación: utf-8):\n",
      "  - Columna 'CLAVE_ENTIDAD' tiene un solo tipo de dato: int\n",
      "  - Columna 'ENTIDAD' tiene un solo tipo de dato: str\n",
      "  - Columna 'CLAVE_MUNICIPIO' tiene un solo tipo de dato: int\n",
      "  - Columna 'MUNICIPIO' tiene un solo tipo de dato: str\n",
      "  - Columna 'CLUES' tiene un solo tipo de dato: str\n",
      "  - Columna 'NOMBRE_CLUES' tiene un solo tipo de dato: str\n",
      "  - Columna 'MES' tiene un solo tipo de dato: int\n",
      "  - Columna 'ANIO' tiene un solo tipo de dato: int\n",
      "  - Columna 'ADL02' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL03' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL05' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL06' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL08' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL09' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL11' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL12' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL14' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL15' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL17' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL18' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM02' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM03' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM05' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM06' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM08' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM09' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM11' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM12' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM14' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM15' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM17' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM18' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC02' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC03' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC05' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC06' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC08' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC09' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC11' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC12' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC14' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC15' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC17' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC18' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA02' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA03' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA05' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA06' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA08' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA09' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA11' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA12' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA14' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA15' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA17' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA18' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB02' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB03' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB05' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB06' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB08' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB09' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB11' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB12' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB14' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB15' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB17' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB18' tiene un solo tipo de dato: float\n",
      "  - Columna 'FRS01' tiene un solo tipo de dato: float\n",
      "  - Columna 'FRS02' tiene un solo tipo de dato: float\n",
      "  - Columna 'FRS03' tiene un solo tipo de dato: float\n",
      "  - Columna 'FRS04' tiene un solo tipo de dato: float\n",
      "  - Columna 'HBA01' tiene un solo tipo de dato: float\n",
      "  - Columna 'HBA02' tiene un solo tipo de dato: float\n",
      "  - Columna 'HBA03' tiene un solo tipo de dato: float\n",
      "  - Columna 'PDM02' tiene un solo tipo de dato: float\n",
      "  - Columna 'PDM03' tiene un solo tipo de dato: float\n",
      "  - Columna 'PMA01' tiene un solo tipo de dato: float\n",
      "  - Columna 'RUN01' tiene un solo tipo de dato: float\n",
      "\n",
      "Análisis de tipos de datos en DA_EC_SIS_2019_normalizado.csv (codificación: utf-8):\n",
      "  - Columna 'CLAVE_ENTIDAD' tiene un solo tipo de dato: int\n",
      "  - Columna 'ENTIDAD' tiene un solo tipo de dato: str\n",
      "  - Columna 'CLAVE_MUNICIPIO' tiene un solo tipo de dato: int\n",
      "  - Columna 'MUNICIPIO' tiene un solo tipo de dato: str\n",
      "  - Columna 'CLUES' tiene un solo tipo de dato: str\n",
      "  - Columna 'NOMBRE_CLUES' tiene un solo tipo de dato: str\n",
      "  - Columna 'MES' tiene un solo tipo de dato: int\n",
      "  - Columna 'ANIO' tiene un solo tipo de dato: int\n",
      "  - Columna 'ADL02' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL03' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL05' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL06' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL08' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL09' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL11' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL12' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL14' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL15' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL17' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL18' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM02' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM03' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM05' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM06' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM08' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM09' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM11' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM12' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM14' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM15' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM17' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM18' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC02' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC03' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC05' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC06' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC08' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC09' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC11' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC12' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC14' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC15' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC17' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC18' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA02' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA03' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA05' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA06' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA08' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA09' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA11' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA12' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA14' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA15' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA17' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA18' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB02' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB03' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB05' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB06' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB08' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB09' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB11' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB12' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB14' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB15' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB17' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB18' tiene un solo tipo de dato: float\n",
      "  - Columna 'FRS01' tiene un solo tipo de dato: float\n",
      "  - Columna 'FRS02' tiene un solo tipo de dato: float\n",
      "  - Columna 'FRS03' tiene un solo tipo de dato: float\n",
      "  - Columna 'FRS04' tiene un solo tipo de dato: float\n",
      "  - Columna 'HBA01' tiene un solo tipo de dato: float\n",
      "  - Columna 'HBA02' tiene un solo tipo de dato: float\n",
      "  - Columna 'HBA03' tiene un solo tipo de dato: float\n",
      "  - Columna 'PDM02' tiene un solo tipo de dato: float\n",
      "  - Columna 'PDM03' tiene un solo tipo de dato: float\n",
      "  - Columna 'PMA01' tiene un solo tipo de dato: float\n",
      "  - Columna 'RUN01' tiene un solo tipo de dato: float\n",
      "Error al procesar DA_EC_SIS_2020_normalizado.csv con codificación utf-8: 'utf-8' codec can't decode byte 0xc9 in position 11: invalid continuation byte\n",
      "\n",
      "Análisis de tipos de datos en DA_EC_SIS_2020_normalizado.csv (codificación: latin1):\n",
      "  - Columna 'CLAVE_ENTIDAD' tiene un solo tipo de dato: int\n",
      "  - Columna 'ENTIDAD' tiene un solo tipo de dato: str\n",
      "  - Columna 'CLAVE_MUNICIPIO' tiene un solo tipo de dato: int\n",
      "  - Columna 'MUNICIPIO' tiene un solo tipo de dato: str\n",
      "  - Columna 'CLUES' tiene un solo tipo de dato: str\n",
      "  - Columna 'NOMBRE_CLUES' tiene un solo tipo de dato: str\n",
      "  - Columna 'MES' tiene un solo tipo de dato: int\n",
      "  - Columna 'ANIO' tiene un solo tipo de dato: int\n",
      "  - Columna 'ADL02' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL03' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL05' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL06' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL08' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL09' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL11' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL12' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL14' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL15' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL17' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL18' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM02' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM03' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM05' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM06' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM08' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM09' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM11' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM12' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM14' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM15' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM17' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM18' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC02' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC03' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC05' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC06' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC08' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC09' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC11' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC12' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC14' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC15' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC17' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC18' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA02' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA03' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA05' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA06' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA08' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA09' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA11' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA12' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA14' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA15' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA17' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA18' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB02' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB03' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB05' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB06' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB08' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB09' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB11' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB12' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB14' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB15' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB17' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB18' tiene un solo tipo de dato: float\n",
      "  - Columna 'FRS01' tiene un solo tipo de dato: float\n",
      "  - Columna 'FRS02' tiene un solo tipo de dato: float\n",
      "  - Columna 'FRS03' tiene un solo tipo de dato: float\n",
      "  - Columna 'FRS04' tiene un solo tipo de dato: float\n",
      "  - Columna 'HBA01' tiene un solo tipo de dato: float\n",
      "  - Columna 'HBA02' tiene un solo tipo de dato: float\n",
      "  - Columna 'HBA03' tiene un solo tipo de dato: float\n",
      "  - Columna 'PDM02' tiene un solo tipo de dato: float\n",
      "  - Columna 'PDM03' tiene un solo tipo de dato: float\n",
      "  - Columna 'PMA01' tiene un solo tipo de dato: float\n",
      "  - Columna 'RUN01' tiene un solo tipo de dato: float\n",
      "Error al procesar DA_EC_SIS_2021_normalizado.csv con codificación utf-8: 'utf-8' codec can't decode byte 0xc9 in position 11: invalid continuation byte\n",
      "\n",
      "Análisis de tipos de datos en DA_EC_SIS_2021_normalizado.csv (codificación: latin1):\n",
      "  - Columna 'CLAVE_ENTIDAD' tiene un solo tipo de dato: int\n",
      "  - Columna 'ENTIDAD' tiene un solo tipo de dato: str\n",
      "  - Columna 'CLAVE_MUNICIPIO' tiene un solo tipo de dato: int\n",
      "  - Columna 'MUNICIPIO' tiene un solo tipo de dato: str\n",
      "  - Columna 'CLUES' tiene un solo tipo de dato: str\n",
      "  - Columna 'NOMBRE_CLUES' tiene un solo tipo de dato: str\n",
      "  - Columna 'MES' tiene un solo tipo de dato: int\n",
      "  - Columna 'ANIO' tiene un solo tipo de dato: int\n",
      "  - Columna 'ADL02' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL03' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL05' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL06' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL08' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL09' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL11' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL12' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL14' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL15' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL17' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL18' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM02' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM03' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM05' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM06' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM08' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM09' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM11' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM12' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM14' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM15' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM17' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM18' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM19' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM20' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM21' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM22' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM23' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC02' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC03' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC05' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC06' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC08' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC09' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC11' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC12' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC14' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC15' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC17' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC18' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA02' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA03' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA05' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA06' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA08' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA09' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA11' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA12' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA14' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA15' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA17' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA18' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB02' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB03' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB05' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB06' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB08' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB09' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB11' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB12' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB14' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB15' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB17' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB18' tiene un solo tipo de dato: float\n",
      "  - Columna 'FRS01' tiene un solo tipo de dato: float\n",
      "  - Columna 'FRS02' tiene un solo tipo de dato: float\n",
      "  - Columna 'FRS03' tiene un solo tipo de dato: float\n",
      "  - Columna 'FRS04' tiene un solo tipo de dato: float\n",
      "  - Columna 'HBA01' tiene un solo tipo de dato: float\n",
      "  - Columna 'HBA02' tiene un solo tipo de dato: float\n",
      "  - Columna 'HBA03' tiene un solo tipo de dato: float\n",
      "  - Columna 'PDM02' tiene un solo tipo de dato: float\n",
      "  - Columna 'PDM03' tiene un solo tipo de dato: float\n",
      "  - Columna 'PMA01' tiene un solo tipo de dato: float\n",
      "  - Columna 'PMA02' tiene un solo tipo de dato: float\n",
      "  - Columna 'RUN01' tiene un solo tipo de dato: float\n",
      "Error al procesar DA_EC_SIS_2022_normalizado.csv con codificación utf-8: 'utf-8' codec can't decode byte 0xc9 in position 11: invalid continuation byte\n",
      "\n",
      "Análisis de tipos de datos en DA_EC_SIS_2022_normalizado.csv (codificación: latin1):\n",
      "  - Columna 'CLAVE_ENTIDAD' tiene un solo tipo de dato: int\n",
      "  - Columna 'ENTIDAD' tiene un solo tipo de dato: str\n",
      "  - Columna 'CLAVE_MUNICIPIO' tiene un solo tipo de dato: int\n",
      "  - Columna 'MUNICIPIO' tiene un solo tipo de dato: str\n",
      "  - Columna 'CLUES' tiene un solo tipo de dato: str\n",
      "  - Columna 'NOMBRE_CLUES' tiene un solo tipo de dato: str\n",
      "  - Columna 'MES' tiene un solo tipo de dato: int\n",
      "  - Columna 'ANIO' tiene un solo tipo de dato: int\n",
      "  - Columna 'ADL02' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL03' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL05' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL06' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL08' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL09' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL11' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL12' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL14' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL15' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL17' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL18' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM02' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM03' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM05' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM06' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM08' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM09' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM11' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM12' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM14' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM15' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM17' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM18' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM19' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM20' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM21' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM22' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM23' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC02' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC03' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC05' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC06' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC08' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC09' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC11' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC12' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC14' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC15' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC17' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC18' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA02' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA03' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA05' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA06' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA08' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA09' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA11' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA12' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA14' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA15' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA17' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA18' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB02' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB03' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB05' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB06' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB08' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB09' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB11' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB12' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB14' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB15' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB17' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB18' tiene un solo tipo de dato: float\n",
      "  - Columna 'FRS01' tiene un solo tipo de dato: float\n",
      "  - Columna 'FRS02' tiene un solo tipo de dato: float\n",
      "  - Columna 'FRS03' tiene un solo tipo de dato: float\n",
      "  - Columna 'FRS04' tiene un solo tipo de dato: float\n",
      "  - Columna 'HBA01' tiene un solo tipo de dato: float\n",
      "  - Columna 'HBA02' tiene un solo tipo de dato: float\n",
      "  - Columna 'HBA03' tiene un solo tipo de dato: float\n",
      "  - Columna 'PDM02' tiene un solo tipo de dato: float\n",
      "  - Columna 'PDM03' tiene un solo tipo de dato: float\n",
      "  - Columna 'PMA01' tiene un solo tipo de dato: float\n",
      "  - Columna 'PMA02' tiene un solo tipo de dato: float\n",
      "  - Columna 'RUN01' tiene un solo tipo de dato: float\n",
      "Error al procesar DA_EC_SIS_2023_normalizado.csv con codificación utf-8: 'utf-8' codec can't decode byte 0xc9 in position 11: invalid continuation byte\n",
      "\n",
      "Análisis de tipos de datos en DA_EC_SIS_2023_normalizado.csv (codificación: latin1):\n",
      "  - Columna 'CLAVE_ENTIDAD' tiene un solo tipo de dato: int\n",
      "  - Columna 'ENTIDAD' tiene un solo tipo de dato: str\n",
      "  - Columna 'CLAVE_MUNICIPIO' tiene un solo tipo de dato: int\n",
      "  - Columna 'MUNICIPIO' tiene un solo tipo de dato: str\n",
      "  - Columna 'CLUES' tiene un solo tipo de dato: str\n",
      "  - Columna 'NOMBRE_CLUES' tiene un solo tipo de dato: str\n",
      "  - Columna 'MES' tiene un solo tipo de dato: int\n",
      "  - Columna 'ANIO' tiene un solo tipo de dato: int\n",
      "  - Columna 'ADL02' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL03' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL05' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL06' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL08' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL09' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL11' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL12' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL14' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL15' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL17' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADL18' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM02' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM03' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM05' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM06' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM08' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM09' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM11' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM12' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM14' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM15' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM17' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM18' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM19' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM20' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM21' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM22' tiene un solo tipo de dato: float\n",
      "  - Columna 'ADM23' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC02' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC03' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC05' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC06' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC08' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC09' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC11' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC12' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC14' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC15' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC17' tiene un solo tipo de dato: float\n",
      "  - Columna 'AEC18' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA02' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA03' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA05' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA06' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA08' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA09' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA11' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA12' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA14' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA15' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA17' tiene un solo tipo de dato: float\n",
      "  - Columna 'AHA18' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB02' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB03' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB05' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB06' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB08' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB09' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB11' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB12' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB14' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB15' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB17' tiene un solo tipo de dato: float\n",
      "  - Columna 'AOB18' tiene un solo tipo de dato: float\n",
      "  - Columna 'FRS01' tiene un solo tipo de dato: float\n",
      "  - Columna 'FRS02' tiene un solo tipo de dato: float\n",
      "  - Columna 'FRS03' tiene un solo tipo de dato: float\n",
      "  - Columna 'FRS04' tiene un solo tipo de dato: float\n",
      "  - Columna 'HBA01' tiene un solo tipo de dato: float\n",
      "  - Columna 'HBA02' tiene un solo tipo de dato: float\n",
      "  - Columna 'HBA03' tiene un solo tipo de dato: float\n",
      "  - Columna 'PDM02' tiene un solo tipo de dato: float\n",
      "  - Columna 'PDM03' tiene un solo tipo de dato: float\n",
      "  - Columna 'PMA01' tiene un solo tipo de dato: float\n",
      "  - Columna 'PMA02' tiene un solo tipo de dato: float\n",
      "  - Columna 'RUN01' tiene un solo tipo de dato: float\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directorio donde se encuentran los archivos CSV\n",
    "directory = \"Bases saludo taller\"\n",
    "\n",
    "# Codificaciones a intentar\n",
    "encodings = [\"utf-8\", \"latin1\", \"iso-8859-1\"]\n",
    "\n",
    "# Iterar sobre los archivos normalizados\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\"_normalizado.csv\"):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        processed = False  # Bandera para verificar si el archivo se procesó correctamente\n",
    "\n",
    "        for encoding in encodings:\n",
    "            try:\n",
    "                # Leer el archivo con diferentes codificaciones\n",
    "                df = pd.read_csv(file_path, encoding=encoding, low_memory=False)\n",
    "\n",
    "                print(f\"\\nAnálisis de tipos de datos en {filename} (codificación: {encoding}):\")\n",
    "\n",
    "                # Iterar sobre cada columna\n",
    "                for col in df.columns:\n",
    "                    # Obtener tipos de datos únicos en la columna\n",
    "                    unique_types = df[col].dropna().apply(type).unique()\n",
    "\n",
    "                    # Reportar si hay más de un tipo de dato\n",
    "                    if len(unique_types) > 1:\n",
    "                        print(f\"  - Columna '{col}' tiene múltiples tipos de datos: {[t.__name__ for t in unique_types]}\")\n",
    "                    else:\n",
    "                        print(f\"  - Columna '{col}' tiene un solo tipo de dato: {unique_types[0].__name__ if unique_types.size > 0 else 'vacío'}\")\n",
    "\n",
    "                processed = True  # Marcar como procesado correctamente\n",
    "                break  # Salir del bucle si la lectura fue exitosa\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error al procesar {filename} con codificación {encoding}: {e}\")\n",
    "                continue  # Probar con la siguiente codificación\n",
    "\n",
    "        if not processed:\n",
    "            print(f\"No se pudo procesar {filename} con ninguna de las codificaciones.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mis bases tienen esta forma, deseo crear bases de datos relacionales\n",
    "CLAVE_ENTIDAD,ENTIDAD,CLAVE_MUNICIPIO,MUNICIPIO,CLUES,NOMBRE_CLUES,MES,ANIO,ADL02,ADL03,ADL05,ADL06,ADL08,ADL09,ADL11,ADL12,ADL14,ADL15,ADL17,ADL18,ADM02,ADM03,ADM05,ADM06,ADM08,ADM09,ADM11,ADM12,ADM14,ADM15,ADM17,ADM18,AEC02,AEC03,AEC05,AEC06,AEC08,AEC09,AEC11,AEC12,AEC14,AEC15,AEC17,AEC18,AHA02,AHA03,AHA05,AHA06,AHA08,AHA09,AHA11,AHA12,AHA14,AHA15,AHA17,AHA18,AOB02,AOB03,AOB05,AOB06,AOB08,AOB09,AOB11,AOB12,AOB14,AOB15,AOB17,AOB18,FRS01,FRS02,FRS03,FRS04,HBA01,HBA02,HBA03,PDM02,PDM03,PMA01,RUN01\n",
    "\n",
    "Se me ocurre que tengan esta forma, consideras que es apropiada?\n",
    "\n",
    "Tabla \"Unidades_Salud: CLAVE_ENTIDAD,ENTIDAD,CLAVE_MUNICIPIO,MUNICIPIO,CLUES,NOMBRE_CLUES\n",
    "\n",
    "Tabla \"Enfermedades\": construida generando una columna llamada \"Codigo_enfermedades\" con las columnas que están despues de anio, ya que estas son justo registro de diversas enfermedas, y a estas vamos a generarles un identificador unico \"ID_Enfermedad\". \n",
    "\n",
    "Tabla que se llame \"Casos_Enfermedades\" vamos a utilizar de nuevo CLUES que es donde se registran las enfermedades, se va a utilizar el \"ID_Enfermedad\" que generamos antes y que es el registro unico de cada una de ellas. También aquí estará MEs, ANIO y una columna llamada CONTEO. \n",
    "\n",
    "Quiero que cada vez que se ejecute el codigo, solo se procese una de las bases que terminan en \"_normalizado\". El resultado se guardará en una subcarpeta en \"Bases salud taller\" que tenga el nombre \"Base-año\" donde el año será extraido del nombre del archivo csv terminado en \"_normalizado\", el año estará justo antes de ese final. Si la carpeta a generar tiene el nombre de ese archivo, no lo proceses. Debes convertir cada archivo en 3 bases csv que sirvan luego para enviar a una base SQL relacional. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo DA_EC_SIS_2010_normalizado.csv procesado y guardado en Bases saludo taller\\Base-2010.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Directorio principal\n",
    "directory = \"Bases saludo taller\"\n",
    "\n",
    "# Iterar sobre los archivos normalizados\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\"_normalizado.csv\"):\n",
    "        # Extraer el año del nombre del archivo\n",
    "        match = re.search(r'(\\d{4})_normalizado\\.csv$', filename)\n",
    "        if match:\n",
    "            year = match.group(1)\n",
    "            output_dir = os.path.join(directory, f\"Base-{year}\")\n",
    "\n",
    "            # Si la carpeta ya existe, omitir el archivo\n",
    "            if os.path.exists(output_dir):\n",
    "                print(f\"El archivo {filename} ya ha sido procesado. Saltando...\")\n",
    "                continue\n",
    "\n",
    "            # Crear la carpeta de salida\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            file_path = os.path.join(directory, filename)\n",
    "\n",
    "            try:\n",
    "                # Leer el archivo\n",
    "                df = pd.read_csv(file_path, encoding='utf-8', low_memory=False)\n",
    "\n",
    "                # Crear tabla Unidades_Salud\n",
    "                unidades_cols = [\"CLAVE_ENTIDAD\", \"ENTIDAD\", \"CLAVE_MUNICIPIO\", \"MUNICIPIO\", \"CLUES\", \"NOMBRE_CLUES\"]\n",
    "                df_unidades_salud = df[unidades_cols].drop_duplicates()\n",
    "\n",
    "                # Crear tabla Enfermedades\n",
    "                enfermedad_cols = [col for col in df.columns if col not in unidades_cols + [\"MES\", \"ANIO\"]]\n",
    "                enfermedades = [{\"ID_ENFERMEDAD\": idx + 1, \"CODIGO_ENFERMEDAD\": col} \n",
    "                                 for idx, col in enumerate(enfermedad_cols)]\n",
    "                df_enfermedades = pd.DataFrame(enfermedades)\n",
    "\n",
    "                # Crear tabla Casos_Enfermedades\n",
    "                casos_enfermedades = []\n",
    "                for index, row in df.iterrows():\n",
    "                    for col in enfermedad_cols:\n",
    "                        conteo = row[col]\n",
    "                        if pd.notna(conteo) and conteo != \"\":\n",
    "                            casos_enfermedades.append({\n",
    "                                \"CLUES\": row[\"CLUES\"],\n",
    "                                \"ID_ENFERMEDAD\": df_enfermedades[df_enfermedades[\"CODIGO_ENFERMEDAD\"] == col][\"ID_ENFERMEDAD\"].values[0],\n",
    "                                \"MES\": row[\"MES\"],\n",
    "                                \"ANIO\": row[\"ANIO\"],\n",
    "                                \"CONTEO\": conteo\n",
    "                            })\n",
    "\n",
    "                df_casos_enfermedades = pd.DataFrame(casos_enfermedades)\n",
    "\n",
    "                # Guardar los CSV en la carpeta correspondiente\n",
    "                df_unidades_salud.to_csv(os.path.join(output_dir, \"Unidades_Salud.csv\"), index=False)\n",
    "                df_enfermedades.to_csv(os.path.join(output_dir, \"Enfermedades.csv\"), index=False)\n",
    "                df_casos_enfermedades.to_csv(os.path.join(output_dir, \"Casos_Enfermedades.csv\"), index=False)\n",
    "\n",
    "                print(f\"Archivo {filename} procesado y guardado en {output_dir}.\")\n",
    "                break  # Procesar solo un archivo por ejecución\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error al procesar {filename}: {e}\")\n",
    "                continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dividi mi base usando este codigo para crear bases csv que puedan ser relacionales \n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Directorio principal\n",
    "directory = \"Bases saludo taller\"\n",
    "\n",
    "# Iterar sobre los archivos normalizados\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\"_normalizado.csv\"):\n",
    "        # Extraer el año del nombre del archivo\n",
    "        match = re.search(r'(\\d{4})_normalizado\\.csv$', filename)\n",
    "        if match:\n",
    "            year = match.group(1)\n",
    "            output_dir = os.path.join(directory, f\"Base-{year}\")\n",
    "\n",
    "            # Si la carpeta ya existe, omitir el archivo\n",
    "            if os.path.exists(output_dir):\n",
    "                print(f\"El archivo {filename} ya ha sido procesado. Saltando...\")\n",
    "                continue\n",
    "\n",
    "            # Crear la carpeta de salida\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            file_path = os.path.join(directory, filename)\n",
    "\n",
    "            try:\n",
    "                # Leer el archivo\n",
    "                df = pd.read_csv(file_path, encoding='utf-8', low_memory=False)\n",
    "\n",
    "                # Crear tabla Unidades_Salud\n",
    "                unidades_cols = [\"CLAVE_ENTIDAD\", \"ENTIDAD\", \"CLAVE_MUNICIPIO\", \"MUNICIPIO\", \"CLUES\", \"NOMBRE_CLUES\"]\n",
    "                df_unidades_salud = df[unidades_cols].drop_duplicates()\n",
    "\n",
    "                # Crear tabla Enfermedades\n",
    "                enfermedad_cols = [col for col in df.columns if col not in unidades_cols + [\"MES\", \"ANIO\"]]\n",
    "                enfermedades = [{\"ID_ENFERMEDAD\": idx + 1, \"CODIGO_ENFERMEDAD\": col} \n",
    "                                 for idx, col in enumerate(enfermedad_cols)]\n",
    "                df_enfermedades = pd.DataFrame(enfermedades)\n",
    "\n",
    "                # Crear tabla Casos_Enfermedades\n",
    "                casos_enfermedades = []\n",
    "                for index, row in df.iterrows():\n",
    "                    for col in enfermedad_cols:\n",
    "                        conteo = row[col]\n",
    "                        if pd.notna(conteo) and conteo != \"\":\n",
    "                            casos_enfermedades.append({\n",
    "                                \"CLUES\": row[\"CLUES\"],\n",
    "                                \"ID_ENFERMEDAD\": df_enfermedades[df_enfermedades[\"CODIGO_ENFERMEDAD\"] == col][\"ID_ENFERMEDAD\"].values[0],\n",
    "                                \"MES\": row[\"MES\"],\n",
    "                                \"ANIO\": row[\"ANIO\"],\n",
    "                                \"CONTEO\": conteo\n",
    "                            })\n",
    "\n",
    "                df_casos_enfermedades = pd.DataFrame(casos_enfermedades)\n",
    "\n",
    "                # Guardar los CSV en la carpeta correspondiente\n",
    "                df_unidades_salud.to_csv(os.path.join(output_dir, \"Unidades_Salud.csv\"), index=False)\n",
    "                df_enfermedades.to_csv(os.path.join(output_dir, \"Enfermedades.csv\"), index=False)\n",
    "                df_casos_enfermedades.to_csv(os.path.join(output_dir, \"Casos_Enfermedades.csv\"), index=False)\n",
    "\n",
    "                print(f\"Archivo {filename} procesado y guardado en {output_dir}.\")\n",
    "                break  # Procesar solo un archivo por ejecución\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error al procesar {filename}: {e}\")\n",
    "                continue\n",
    "\n",
    "ahora quiero crear la base en MySQL que sea capaz de recibir los datos que acabo de generar\n",
    "los datos de conexion a la base son \n",
    "\n",
    "        host=\"127.0.0.1\",\n",
    "        user=\"root\",\n",
    "        password=\"PruebaEstu2012\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "from mysql.connector import errorcode\n",
    "\n",
    "# Datos de conexión a MySQL\n",
    "config = {\n",
    "    'host': \"127.0.0.1\",\n",
    "    'user': \"root\",\n",
    "    'password': \"PruebaEstu2012\"\n",
    "}\n",
    "\n",
    "# Nombre de la base de datos\n",
    "database_name = \"Salud_DB\"\n",
    "\n",
    "# Conectar a MySQL\n",
    "try:\n",
    "    conn = mysql.connector.connect(**config)\n",
    "    cursor = conn.cursor()\n",
    "    print(\"Conexión exitosa a MySQL.\")\n",
    "except mysql.connector.Error as err:\n",
    "    print(f\"Error de conexión: {err}\")\n",
    "    exit()\n",
    "\n",
    "# Crear la base de datos si no existe\n",
    "try:\n",
    "    cursor.execute(f\"CREATE DATABASE IF NOT EXISTS {database_name}\")\n",
    "    print(f\"Base de datos '{database_name}' creada o ya existente.\")\n",
    "except mysql.connector.Error as err:\n",
    "    print(f\"Error al crear la base de datos: {err}\")\n",
    "    exit()\n",
    "\n",
    "# Conectar a la base de datos creada\n",
    "conn.database = database_name\n",
    "\n",
    "# Definición de tablas\n",
    "tables = {\n",
    "    \"Unidades_Salud\": (\n",
    "        \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS Unidades_Salud (\n",
    "            CLAVE_ENTIDAD VARCHAR(5),\n",
    "            ENTIDAD VARCHAR(255),\n",
    "            CLAVE_MUNICIPIO VARCHAR(5),\n",
    "            MUNICIPIO VARCHAR(255),\n",
    "            CLUES VARCHAR(20) PRIMARY KEY,\n",
    "            NOMBRE_CLUES VARCHAR(255)\n",
    "        )\n",
    "        \"\"\"\n",
    "    ),\n",
    "    \"Enfermedades\": (\n",
    "        \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS Enfermedades (\n",
    "            ID_ENFERMEDAD INT PRIMARY KEY,\n",
    "            CODIGO_ENFERMEDAD VARCHAR(20)\n",
    "        )\n",
    "        \"\"\"\n",
    "    ),\n",
    "    \"Casos_Enfermedades\": (\n",
    "        \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS Casos_Enfermedades (\n",
    "            ID INT AUTO_INCREMENT PRIMARY KEY,\n",
    "            CLUES VARCHAR(20),\n",
    "            ID_ENFERMEDAD INT,\n",
    "            MES INT,\n",
    "            ANIO INT,\n",
    "            CONTEO INT,\n",
    "            FOREIGN KEY (CLUES) REFERENCES Unidades_Salud(CLUES),\n",
    "            FOREIGN KEY (ID_ENFERMEDAD) REFERENCES Enfermedades(ID_ENFERMEDAD)\n",
    "        )\n",
    "        \"\"\"\n",
    "    )\n",
    "}\n",
    "\n",
    "# Crear tablas en la base de datos\n",
    "for table_name, ddl in tables.items():\n",
    "    try:\n",
    "        cursor.execute(ddl)\n",
    "        print(f\"Tabla '{table_name}' creada o ya existente.\")\n",
    "    except mysql.connector.Error as err:\n",
    "        print(f\"Error al crear la tabla '{table_name}': {err}\")\n",
    "\n",
    "# Ruta al directorio de las bases\n",
    "directory = \"Bases saludo taller\"\n",
    "\n",
    "# Cargar datos de cada carpeta Base-<AÑO>\n",
    "for subdir in os.listdir(directory):\n",
    "    if subdir.startswith(\"Base-\"):\n",
    "        subdir_path = os.path.join(directory, subdir)\n",
    "        print(f\"\\nProcesando datos de {subdir}...\")\n",
    "\n",
    "        try:\n",
    "            # Cargar Unidades_Salud\n",
    "            df_unidades = pd.read_csv(os.path.join(subdir_path, \"Unidades_Salud.csv\"))\n",
    "            for _, row in df_unidades.iterrows():\n",
    "                cursor.execute(\"\"\"\n",
    "                    INSERT IGNORE INTO Unidades_Salud (CLAVE_ENTIDAD, ENTIDAD, CLAVE_MUNICIPIO, MUNICIPIO, CLUES, NOMBRE_CLUES)\n",
    "                    VALUES (%s, %s, %s, %s, %s, %s)\n",
    "                \"\"\", tuple(row))\n",
    "\n",
    "            # Cargar Enfermedades\n",
    "            df_enfermedades = pd.read_csv(os.path.join(subdir_path, \"Enfermedades.csv\"))\n",
    "            for _, row in df_enfermedades.iterrows():\n",
    "                cursor.execute(\"\"\"\n",
    "                    INSERT IGNORE INTO Enfermedades (ID_ENFERMEDAD, CODIGO_ENFERMEDAD)\n",
    "                    VALUES (%s, %s)\n",
    "                \"\"\", tuple(row))\n",
    "\n",
    "            # Cargar Casos_Enfermedades\n",
    "            df_casos = pd.read_csv(os.path.join(subdir_path, \"Casos_Enfermedades.csv\"))\n",
    "            for _, row in df_casos.iterrows():\n",
    "                cursor.execute(\"\"\"\n",
    "                    INSERT INTO Casos_Enfermedades (CLUES, ID_ENFERMEDAD, MES, ANIO, CONTEO)\n",
    "                    VALUES (%s, %s, %s, %s, %s)\n",
    "                \"\"\", tuple(row))\n",
    "\n",
    "            conn.commit()\n",
    "            print(f\"Datos de {subdir} cargados exitosamente.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error al cargar datos de {subdir}: {e}\")\n",
    "\n",
    "# Cerrar la conexión\n",
    "cursor.close()\n",
    "conn.close()\n",
    "print(\"\\nProceso de carga finalizado.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "utilizando las bases de datos que están en \"Bases saludo taller\\Base-2010\"  y que convertimos en csv relacionales antes, dame el codigo para enviarlas a esta base de datos en SQL que acabas de crear \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conexión exitosa a MySQL.\n",
      "Datos de 'Base-2010' cargados exitosamente.\n",
      "\n",
      "Proceso de carga finalizado.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "from mysql.connector import errorcode\n",
    "\n",
    "# Datos de conexión a MySQL\n",
    "config = {\n",
    "    'host': \"127.0.0.1\",\n",
    "    'user': \"root\",\n",
    "    'password': \"PruebaEstu2012\"\n",
    "}\n",
    "\n",
    "# Nombre de la base de datos\n",
    "database_name = \"Salud_DB\"\n",
    "\n",
    "# Conectar a MySQL\n",
    "try:\n",
    "    conn = mysql.connector.connect(**config)\n",
    "    cursor = conn.cursor()\n",
    "    print(\"Conexión exitosa a MySQL.\")\n",
    "except mysql.connector.Error as err:\n",
    "    print(f\"Error de conexión: {err}\")\n",
    "    exit()\n",
    "\n",
    "# Conectar a la base de datos creada\n",
    "conn.database = database_name\n",
    "\n",
    "# Ruta al directorio de la base Base-2010\n",
    "base_2010_dir = os.path.join(\"Bases saludo taller\", \"Base-2010\")\n",
    "\n",
    "# Verificar si existe la carpeta Base-2010\n",
    "if not os.path.exists(base_2010_dir):\n",
    "    print(\"La carpeta 'Base-2010' no existe en el directorio especificado.\")\n",
    "    exit()\n",
    "\n",
    "try:\n",
    "    # Cargar Unidades_Salud\n",
    "    df_unidades = pd.read_csv(os.path.join(base_2010_dir, \"Unidades_Salud.csv\"))\n",
    "    for _, row in df_unidades.iterrows():\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT IGNORE INTO Unidades_Salud (CLAVE_ENTIDAD, ENTIDAD, CLAVE_MUNICIPIO, MUNICIPIO, CLUES, NOMBRE_CLUES)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s)\n",
    "        \"\"\", tuple(row))\n",
    "\n",
    "    # Cargar Enfermedades\n",
    "    df_enfermedades = pd.read_csv(os.path.join(base_2010_dir, \"Enfermedades.csv\"))\n",
    "    for _, row in df_enfermedades.iterrows():\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT IGNORE INTO Enfermedades (ID_ENFERMEDAD, CODIGO_ENFERMEDAD)\n",
    "            VALUES (%s, %s)\n",
    "        \"\"\", tuple(row))\n",
    "\n",
    "    # Cargar Casos_Enfermedades\n",
    "    df_casos = pd.read_csv(os.path.join(base_2010_dir, \"Casos_Enfermedades.csv\"))\n",
    "    for _, row in df_casos.iterrows():\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO Casos_Enfermedades (CLUES, ID_ENFERMEDAD, MES, ANIO, CONTEO)\n",
    "            VALUES (%s, %s, %s, %s, %s)\n",
    "        \"\"\", tuple(row))\n",
    "\n",
    "    # Confirmar los cambios\n",
    "    conn.commit()\n",
    "    print(f\"Datos de 'Base-2010' cargados exitosamente.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error al cargar datos de 'Base-2010': {e}\")\n",
    "\n",
    "# Cerrar la conexión\n",
    "cursor.close()\n",
    "conn.close()\n",
    "print(\"\\nProceso de carga finalizado.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dame el codigo para "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cantidad total de registros de enfermedades por estado:\n",
      "                ENTIDAD TOTAL_REGISTROS\n",
      "0            GUANAJUATO         2722761\n",
      "1                MEXICO         2692349\n",
      "2              VERACRUZ         2333897\n",
      "3               JALISCO         2137527\n",
      "4              GUERRERO         1750473\n",
      "5      DISTRITO FEDERAL         1408606\n",
      "6               SINALOA         1400137\n",
      "7       SAN LUIS POTOSI         1368342\n",
      "8               TABASCO         1272598\n",
      "9                OAXACA         1242344\n",
      "10               PUEBLA         1223091\n",
      "11            CHIHUAHUA         1177344\n",
      "12            MICHOACAN          971582\n",
      "13              HIDALGO          951484\n",
      "14            ZACATECAS          914936\n",
      "15           NUEVO LEON          870081\n",
      "16           TAMAULIPAS          849886\n",
      "17            QUERETARO          713001\n",
      "18              CHIAPAS          694491\n",
      "19              YUCATAN          675652\n",
      "20             TLAXCALA          653234\n",
      "21               SONORA          631731\n",
      "22              MORELOS          621738\n",
      "23              DURANGO          497658\n",
      "24      BAJA CALIFORNIA          447715\n",
      "25       AGUASCALIENTES          346059\n",
      "26              NAYARIT          340243\n",
      "27         QUINTANA ROO          339808\n",
      "28             CAMPECHE          333802\n",
      "29               COLIMA          283343\n",
      "30             COAHUILA          265127\n",
      "31  BAJA CALIFORNIA SUR          190094\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "import pandas as pd\n",
    "\n",
    "# Datos de conexión a MySQL\n",
    "username = \"root\"\n",
    "password = \"PruebaEstu2012\"\n",
    "host = \"127.0.0.1\"\n",
    "database = \"Salud_DB\"\n",
    "\n",
    "# Crear la URL de conexión\n",
    "connection_url = f\"mysql+mysqlconnector://{username}:{password}@{host}/{database}\"\n",
    "\n",
    "# Crear el motor de conexión\n",
    "engine = create_engine(connection_url)\n",
    "\n",
    "# Consulta SQL para obtener la cantidad total de registros de enfermedades por estado\n",
    "query = \"\"\"\n",
    "    SELECT us.ENTIDAD, SUM(ce.CONTEO) AS TOTAL_REGISTROS\n",
    "    FROM Casos_Enfermedades ce\n",
    "    JOIN Unidades_Salud us ON ce.CLUES = us.CLUES\n",
    "    GROUP BY us.ENTIDAD\n",
    "    ORDER BY TOTAL_REGISTROS DESC;\n",
    "\"\"\"\n",
    "\n",
    "# Conectar y ejecutar la consulta\n",
    "with engine.connect() as connection:\n",
    "    try:\n",
    "        result = connection.execute(text(query))\n",
    "        \n",
    "        # Convertir el resultado en un DataFrame para mejor visualización\n",
    "        df_resultados = pd.DataFrame(result.fetchall(), columns=[\"ENTIDAD\", \"TOTAL_REGISTROS\"])\n",
    "\n",
    "        # Imprimir los resultados\n",
    "        print(\"\\nCantidad total de registros de enfermedades por estado:\")\n",
    "        print(df_resultados)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error al ejecutar la consulta: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "utilicé este codigo para enviar datos a mi base de MySQL\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "from mysql.connector import errorcode\n",
    "\n",
    "# Datos de conexión a MySQL\n",
    "config = {\n",
    "    'host': \"127.0.0.1\",\n",
    "    'user': \"root\",\n",
    "    'password': \"PruebaEstu2012\"\n",
    "}\n",
    "\n",
    "# Nombre de la base de datos\n",
    "database_name = \"Salud_DB\"\n",
    "\n",
    "# Conectar a MySQL\n",
    "try:\n",
    "    conn = mysql.connector.connect(**config)\n",
    "    cursor = conn.cursor()\n",
    "    print(\"Conexión exitosa a MySQL.\")\n",
    "except mysql.connector.Error as err:\n",
    "    print(f\"Error de conexión: {err}\")\n",
    "    exit()\n",
    "\n",
    "# Conectar a la base de datos creada\n",
    "conn.database = database_name\n",
    "\n",
    "# Ruta al directorio de la base Base-2010\n",
    "base_2010_dir = os.path.join(\"Bases saludo taller\", \"Base-2010\")\n",
    "\n",
    "# Verificar si existe la carpeta Base-2010\n",
    "if not os.path.exists(base_2010_dir):\n",
    "    print(\"La carpeta 'Base-2010' no existe en el directorio especificado.\")\n",
    "    exit()\n",
    "\n",
    "try:\n",
    "    # Cargar Unidades_Salud\n",
    "    df_unidades = pd.read_csv(os.path.join(base_2010_dir, \"Unidades_Salud.csv\"))\n",
    "    for _, row in df_unidades.iterrows():\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT IGNORE INTO Unidades_Salud (CLAVE_ENTIDAD, ENTIDAD, CLAVE_MUNICIPIO, MUNICIPIO, CLUES, NOMBRE_CLUES)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s)\n",
    "        \"\"\", tuple(row))\n",
    "\n",
    "    # Cargar Enfermedades\n",
    "    df_enfermedades = pd.read_csv(os.path.join(base_2010_dir, \"Enfermedades.csv\"))\n",
    "    for _, row in df_enfermedades.iterrows():\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT IGNORE INTO Enfermedades (ID_ENFERMEDAD, CODIGO_ENFERMEDAD)\n",
    "            VALUES (%s, %s)\n",
    "        \"\"\", tuple(row))\n",
    "\n",
    "    # Cargar Casos_Enfermedades\n",
    "    df_casos = pd.read_csv(os.path.join(base_2010_dir, \"Casos_Enfermedades.csv\"))\n",
    "    for _, row in df_casos.iterrows():\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO Casos_Enfermedades (CLUES, ID_ENFERMEDAD, MES, ANIO, CONTEO)\n",
    "            VALUES (%s, %s, %s, %s, %s)\n",
    "        \"\"\", tuple(row))\n",
    "\n",
    "    # Confirmar los cambios\n",
    "    conn.commit()\n",
    "    print(f\"Datos de 'Base-2010' cargados exitosamente.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error al cargar datos de 'Base-2010': {e}\")\n",
    "\n",
    "# Cerrar la conexión\n",
    "cursor.close()\n",
    "conn.close()\n",
    "print(\"\\nProceso de carga finalizado.\")\n",
    "\n",
    "\n",
    "dame, el codigo para crear una app de streamlite que contenga graficos relevantes, como por ejemplo, numero de casos por entidad, distribución de enfermedades (top 10), evolución temporal de los casos, casos por unidad de salud (top5). En el caso de las enfermedades, aleatoriamente mapea 10 nombres de enfermedades  a los valores que devuelva la consulta del top (es decir, mapea 10 nombres de enfermedades, no hablo de los datos) ya que actualmente no cuento con el diccionario de datos para definir ese mapeo. Para  el despliegue usa sqlalchemy ya que los datos son voluminosos, que cada grafica esté  una al lado de la otra, dos por fila, crea 6 graficos. en la misma fila del titulo coloca un contador total de casos registrados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "crear como archivo .py y ejecutar con \n",
    "python -m streamlit run nombrearchivo.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 21:41:44.032 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-10 21:41:44.034 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-10 21:41:44.535 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\edupe\\AppData\\Roaming\\Python\\Python313\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-02-10 21:41:44.536 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-10 21:41:45.229 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-10 21:41:45.230 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-10 21:41:45.230 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-10 21:41:45.231 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-10 21:41:45.231 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-10 21:41:45.232 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-10 21:41:45.232 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 99\u001b[0m\n\u001b[0;32m     97\u001b[0m     st\u001b[38;5;241m.\u001b[39msubheader(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNúmero de Casos por Entidad\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     98\u001b[0m     df_entidad \u001b[38;5;241m=\u001b[39m casos_por_entidad()\n\u001b[1;32m---> 99\u001b[0m     \u001b[43mst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbar_chart\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_entidad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_index\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mENTIDAD\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# Gráfico 2: Distribución de Enfermedades (Top 10)\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m col2:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\streamlit\\runtime\\metrics_util.py:409\u001b[0m, in \u001b[0;36mgather_metrics.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    407\u001b[0m         _LOGGER\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to collect command telemetry\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39mex)\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 409\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mnon_optional_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RerunException \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m    411\u001b[0m     \u001b[38;5;66;03m# Duplicated from below, because static analysis tools get confused\u001b[39;00m\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;66;03m# by deferring the rethrow.\u001b[39;00m\n\u001b[0;32m    413\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tracking_activated \u001b[38;5;129;01mand\u001b[39;00m command_telemetry:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\streamlit\\elements\\vega_charts.py:1222\u001b[0m, in \u001b[0;36mVegaChartsMixin.bar_chart\u001b[1;34m(self, data, x, y, x_label, y_label, color, horizontal, stack, width, height, use_container_width)\u001b[0m\n\u001b[0;32m   1215\u001b[0m maybe_raise_stack_warning(\n\u001b[0;32m   1216\u001b[0m     stack,\n\u001b[0;32m   1217\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mst.bar_chart\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1218\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://docs.streamlit.io/develop/api-reference/charts/st.bar_chart\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1219\u001b[0m )\n\u001b[0;32m   1221\u001b[0m \u001b[38;5;66;03m# Offset encodings (used for non-stacked/grouped bar charts) are not supported in Altair < 5.0.0\u001b[39;00m\n\u001b[1;32m-> 1222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtype_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_altair_version_less_than\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m5.0.0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m stack \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m   1223\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StreamlitAPIException(\n\u001b[0;32m   1224\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStreamlit does not support non-stacked (grouped) bar charts with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1225\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAltair 4.x. Please upgrade to Version 5.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1226\u001b[0m     )\n\u001b[0;32m   1228\u001b[0m bar_chart_type \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1229\u001b[0m     ChartType\u001b[38;5;241m.\u001b[39mHORIZONTAL_BAR \u001b[38;5;28;01mif\u001b[39;00m horizontal \u001b[38;5;28;01melse\u001b[39;00m ChartType\u001b[38;5;241m.\u001b[39mVERTICAL_BAR\n\u001b[0;32m   1230\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\streamlit\\type_util.py:420\u001b[0m, in \u001b[0;36mis_altair_version_less_than\u001b[1;34m(v)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mis_altair_version_less_than\u001b[39m(v: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m    402\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return True if the current Altair version is less than the input version.\u001b[39;00m\n\u001b[0;32m    403\u001b[0m \n\u001b[0;32m    404\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    418\u001b[0m \n\u001b[0;32m    419\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 420\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01maltair\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01malt\u001b[39;00m\n\u001b[0;32m    422\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m is_version_less_than(alt\u001b[38;5;241m.\u001b[39m__version__, v)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\altair\\__init__.py:649\u001b[0m\n\u001b[0;32m    645\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__dir__\u001b[39m():\n\u001b[0;32m    646\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m __all__\n\u001b[1;32m--> 649\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01maltair\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvegalite\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    650\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01maltair\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvegalite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv5\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschema\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict\n\u001b[0;32m    651\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01maltair\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjupyter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m JupyterChart\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\altair\\vegalite\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ruff: noqa: F403\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv5\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\altair\\vegalite\\v5\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ruff: noqa: F401, F403, F405\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01maltair\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexpr\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datum\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01maltair\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvegalite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv5\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m api, compiler, schema\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01maltair\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvegalite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv5\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\altair\\expr\\__init__.py:11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING, Any\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01maltair\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexpr\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ConstExpression, FunctionExpression\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01maltair\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvegalite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv5\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschema\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExprRef \u001b[38;5;28;01mas\u001b[39;00m _ExprRef\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mversion_info \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m12\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\altair\\expr\\core.py:6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING, Any, Literal, Union\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01maltair\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SchemaBase\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\altair\\utils\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     SHORTHAND_KEYS,\n\u001b[0;32m      3\u001b[0m     display_traceback,\n\u001b[0;32m      4\u001b[0m     infer_encoding_types,\n\u001b[0;32m      5\u001b[0m     infer_vegalite_type_for_pandas,\n\u001b[0;32m      6\u001b[0m     parse_shorthand,\n\u001b[0;32m      7\u001b[0m     sanitize_narwhals_dataframe,\n\u001b[0;32m      8\u001b[0m     sanitize_pandas_dataframe,\n\u001b[0;32m      9\u001b[0m     update_nested,\n\u001b[0;32m     10\u001b[0m     use_signature,\n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeprecation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AltairDeprecationWarning, deprecated, deprecated_warn\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhtml\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m spec_to_html\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\altair\\utils\\core.py:17\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01moperator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m itemgetter\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING, Any, Callable, Literal, TypeVar, cast, overload\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjsonschema\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnarwhals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstable\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnw\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnarwhals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstable\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdependencies\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_pandas_dataframe, is_polars_dataframe\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\jsonschema\\__init__.py:16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjsonschema\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_types\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TypeChecker\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjsonschema\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SchemaError, ValidationError\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjsonschema\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidators\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     17\u001b[0m     Draft3Validator,\n\u001b[0;32m     18\u001b[0m     Draft4Validator,\n\u001b[0;32m     19\u001b[0m     Draft6Validator,\n\u001b[0;32m     20\u001b[0m     Draft7Validator,\n\u001b[0;32m     21\u001b[0m     Draft201909Validator,\n\u001b[0;32m     22\u001b[0m     Draft202012Validator,\n\u001b[0;32m     23\u001b[0m     validate,\n\u001b[0;32m     24\u001b[0m )\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getattr__\u001b[39m(name):\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__version__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\jsonschema\\validators.py:25\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mreferencing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mreferencing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjsonschema\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjsonschema\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     26\u001b[0m     _format,\n\u001b[0;32m     27\u001b[0m     _keywords,\n\u001b[0;32m     28\u001b[0m     _legacy_keywords,\n\u001b[0;32m     29\u001b[0m     _types,\n\u001b[0;32m     30\u001b[0m     _typing,\n\u001b[0;32m     31\u001b[0m     _utils,\n\u001b[0;32m     32\u001b[0m     exceptions,\n\u001b[0;32m     33\u001b[0m )\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjsonschema\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotocols\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Validator\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1322\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1262\u001b[0m, in \u001b[0;36m_find_spec\u001b[1;34m(name, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1559\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1533\u001b[0m, in \u001b[0;36m_get_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1632\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(self, fullname, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:152\u001b[0m, in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "import random\n",
    "\n",
    "# Configuración de la conexión a MySQL\n",
    "username = \"root\"\n",
    "password = \"PruebaEstu2012\"\n",
    "host = \"127.0.0.1\"\n",
    "database = \"Salud_DB\"\n",
    "\n",
    "# Crear la URL de conexión\n",
    "connection_url = f\"mysql+mysqlconnector://{username}:{password}@{host}/{database}\"\n",
    "engine = create_engine(connection_url)\n",
    "\n",
    "# Función para obtener el total de casos\n",
    "def obtener_total_casos():\n",
    "    query = \"SELECT SUM(CONTEO) AS TOTAL_CASOS FROM Casos_Enfermedades\"\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(text(query)).fetchone()\n",
    "    return result[0] if result else 0\n",
    "\n",
    "# Consulta para el número de casos por entidad\n",
    "def casos_por_entidad():\n",
    "    query = \"\"\"\n",
    "        SELECT us.ENTIDAD, SUM(ce.CONTEO) AS TOTAL_CASOS\n",
    "        FROM Casos_Enfermedades ce\n",
    "        JOIN Unidades_Salud us ON ce.CLUES = us.CLUES\n",
    "        GROUP BY us.ENTIDAD\n",
    "        ORDER BY TOTAL_CASOS DESC\n",
    "    \"\"\"\n",
    "    with engine.connect() as connection:\n",
    "        df = pd.read_sql_query(text(query), connection)\n",
    "    return df\n",
    "\n",
    "# Consulta para el top 10 de enfermedades\n",
    "def top_enfermedades():\n",
    "    query = \"\"\"\n",
    "        SELECT e.CODIGO_ENFERMEDAD, SUM(ce.CONTEO) AS TOTAL_CASOS\n",
    "        FROM Casos_Enfermedades ce\n",
    "        JOIN Enfermedades e ON ce.ID_ENFERMEDAD = e.ID_ENFERMEDAD\n",
    "        GROUP BY e.CODIGO_ENFERMEDAD\n",
    "        ORDER BY TOTAL_CASOS DESC\n",
    "        LIMIT 10\n",
    "    \"\"\"\n",
    "    with engine.connect() as connection:\n",
    "        df = pd.read_sql_query(text(query), connection)\n",
    "    \n",
    "    # Mapeo aleatorio de nombres de enfermedades\n",
    "    nombres_enfermedades = [\n",
    "        \"Diabetes\", \"Hipertensión\", \"Asma\", \"Artritis\", \"Gripe\",\n",
    "        \"Covid-19\", \"Cáncer\", \"Tuberculosis\", \"Hepatitis\", \"Dengue\"\n",
    "    ]\n",
    "    mapping = dict(zip(df['CODIGO_ENFERMEDAD'], nombres_enfermedades))\n",
    "    df['ENFERMEDAD'] = df['CODIGO_ENFERMEDAD'].map(mapping)\n",
    "    return df\n",
    "\n",
    "# Consulta para la evolución temporal de los casos\n",
    "def evolucion_temporal():\n",
    "    query = \"\"\"\n",
    "        SELECT ANIO, MES, SUM(CONTEO) AS TOTAL_CASOS\n",
    "        FROM Casos_Enfermedades\n",
    "        GROUP BY ANIO, MES\n",
    "        ORDER BY ANIO, MES\n",
    "    \"\"\"\n",
    "    with engine.connect() as connection:\n",
    "        df = pd.read_sql_query(text(query), connection)\n",
    "    return df\n",
    "\n",
    "# Consulta para los casos por unidad de salud (top 5)\n",
    "def casos_por_unidad():\n",
    "    query = \"\"\"\n",
    "        SELECT us.NOMBRE_CLUES, SUM(ce.CONTEO) AS TOTAL_CASOS\n",
    "        FROM Casos_Enfermedades ce\n",
    "        JOIN Unidades_Salud us ON ce.CLUES = us.CLUES\n",
    "        GROUP BY us.NOMBRE_CLUES\n",
    "        ORDER BY TOTAL_CASOS DESC\n",
    "        LIMIT 5\n",
    "    \"\"\"\n",
    "    with engine.connect() as connection:\n",
    "        df = pd.read_sql_query(text(query), connection)\n",
    "    return df\n",
    "\n",
    "# Streamlit App\n",
    "st.set_page_config(layout=\"wide\")\n",
    "\n",
    "# Título y contador total de casos\n",
    "st.title(\"📊 Dashboard de Salud Pública\")\n",
    "total_casos = obtener_total_casos()\n",
    "st.markdown(f\"### Total de Casos Registrados: **{total_casos:,}**\")\n",
    "\n",
    "# Layout para gráficos\n",
    "col1, col2 = st.columns(2)\n",
    "\n",
    "# Gráfico 1: Número de casos por entidad\n",
    "with col1:\n",
    "    st.subheader(\"Número de Casos por Entidad\")\n",
    "    df_entidad = casos_por_entidad()\n",
    "    st.bar_chart(df_entidad.set_index('ENTIDAD'))\n",
    "\n",
    "# Gráfico 2: Distribución de Enfermedades (Top 10)\n",
    "with col2:\n",
    "    st.subheader(\"Distribución de Enfermedades (Top 10)\")\n",
    "    df_enfermedades = top_enfermedades()\n",
    "    st.bar_chart(df_enfermedades.set_index('ENFERMEDAD')['TOTAL_CASOS'])\n",
    "\n",
    "col3, col4 = st.columns(2)\n",
    "\n",
    "# Gráfico 3: Evolución Temporal de los Casos\n",
    "with col3:\n",
    "    st.subheader(\"Evolución Temporal de los Casos\")\n",
    "    df_temporal = evolucion_temporal()\n",
    "    df_temporal['FECHA'] = pd.to_datetime(df_temporal['ANIO'].astype(str) + '-' + df_temporal['MES'].astype(str))\n",
    "    st.line_chart(df_temporal.set_index('FECHA')['TOTAL_CASOS'])\n",
    "\n",
    "# Gráfico 4: Casos por Unidad de Salud (Top 5)\n",
    "with col4:\n",
    "    st.subheader(\"Casos por Unidad de Salud (Top 5)\")\n",
    "    df_unidad = casos_por_unidad()\n",
    "    st.bar_chart(df_unidad.set_index('NOMBRE_CLUES'))\n",
    "\n",
    "col5, col6 = st.columns(2)\n",
    "\n",
    "# Gráfico 5: Porcentaje de Casos por Entidad\n",
    "with col5:\n",
    "    st.subheader(\"Porcentaje de Casos por Entidad\")\n",
    "    st.pyplot(df_entidad.set_index('ENTIDAD').plot.pie(y='TOTAL_CASOS', autopct='%1.1f%%', figsize=(6, 6)).figure)\n",
    "\n",
    "# Gráfico 6: Comparativa de Enfermedades (Top 10)\n",
    "with col6:\n",
    "    st.subheader(\"Comparativa de Enfermedades (Top 10)\")\n",
    "    st.line_chart(df_enfermedades.set_index('ENFERMEDAD')['TOTAL_CASOS'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python -m streamlit run streamlite.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
